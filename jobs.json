[
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://pl.linkedin.com/jobs/view/mlops-engineer-at-emagine-3965424317?position=1&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=pobffLaiNO7YEd6BRxsJWw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "PROJECT INFORMATION:\n\nIndustry: FinTech\n\nRemote work: 100%\n\nBusiness trips: once/month for 2-3 days to the office in Madrid, Spain. Expenses of the business trips are on the client.\n\nOn-boarding: Online or on-site from Madrid if the consultant is open to it.\n\nProject language: English\n\nProject length: 12-18 months (long-term project, at least untill 2027).\n\nStart: ASAP / September 2024\n\nAssignment type: B2B\n\nRemuneration: up to 160 PLN/h net + VAT (depending on the candidate’s experience)\n\nEquipment: Provided by the client.\n\n\n\n\nWe’re looking for a MLOps Engineer to join a team managing the core infrastructure of the company. The team consists of 6 people working with simillar tasks as needed on this position. We’re looking for an additional member not only for one project, but to be a help in development, maintainance and enhancing core functionalities for the whole organization.\n\n\n\n\nRESPONSIBILITIES:\n\n\n\n\nParticipating in the development and maintenance of the core infrastructure.\nBeing exposed to and participating in the end-to-end lifecycle of the projects.\nExtracting, integrating and deployment od API's.\nBeing involved in Cloud projects.\n\n\n\n\nREQUIREMENTS:\n\n\n\n\n3-4 years of experience on a simillar position.\nExperience with development and maintenance of infrastructure.\nExperience in working with API.\nTeamwork orientation.\nCan-do attitude and highly developed problem solving skills.\nStrong analytical and synthetical thinking skills.\nTECH. STACK:\nMandatory skills: Python, Docker, Kubernetes, Jenkins, Git, Linux, MLflow, SQL\n\n\n\n\nNICE TO HAVE:\n\n\n\n\nExperience with Azure or any type of cloud.\nSkills in: PySpark/Spark, Terraform, Airflow, Graylog\nExperience in the FinTech industry.\n\n\n\n\nRECRUITMENT PROCESS:\n\n\n\n\nA short call with our recruiter.\nTechnical interview.\nTest assignment.\nFinal interview with the hiring manager.\n\n\n\n\nWe offer:\n\nLong-term cooperation.\nTransparently built relations based on trust and fair play.\nCo-financed benefits: Medicover card, Multisport card.",
    "companyName": "emagine ",
    "jobLocation": " Poland",
    "jobPostDate": "14 hours ago "
  },
  {
    "jobTitle": "MLops Engineer",
    "applicationLink": "https://pl.linkedin.com/jobs/view/mlops-engineer-at-harvey-nash-poland-3963019089?position=2&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=AFxb457gAhEaj%2FrgQ9qFNA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Salary: 20000-28000 PLN/month gross (80% KUP)\n\nLocation: Warsaw, HYBRID 2days/home\n\nEmployment type: PERMANENT (Umowa o pracę)\n\n\n\n\nAs part of this role you'll be designing, setting up and administering infrastructure for deploying, monitoring, and maintaining ML models.\n\n\n\n\nRole and Responsibilities\n\nCreate a machine learning infrastructure that is highly scalable and supports low latency and high throughput.\nAssist downstream applications with ML models, making sure they are safe, scalable, and obtainable.\nOversee model iterations and guarantee that clients are provided with the most recent version. Establish a rollback procedure in the event that the current model version has problems.\nUse observability and monitoring technologies to keep tabs on the functionality, health, and usage of the platform and its constituent parts. Keep an eye on the functioning of the models that have been deployed, taking note of problems like concept drift, data drift, and model deterioration over time. Recognise problems early on and fix them to keep the system responsive and reliable..\n\n\n\n\nTechnologies in use\n\nPython\nREST\nTerraform\nTensorFlow\nPyTorch\nGithub Actions\nAirflow\nKubernetes\nGrafana\nAWS\nSpark\nSnowflake\nSnowpark\n\n\n\n\nCompetencies and Credentials\n\ndegree in a relevant discipline, such as computer science.\nat least two years of validated microservices industry experience.\nfamiliarity with cloud solutions, orchestration tools (such as AWS, Sagemaker, Airflow, and AWS Step/Lambda), and infrastructure as code (Terraform).\nPossess knowledge of standard ML libraries, ETL, big data tools, and CI/CD (e.g., Docker, Kubernetes, TensorFlow, PyTorch, Spark ML, etc.), as well as MapReduce, Spark, Flink, Kafka, and Unix/Linux with shell.\nfamiliarity with real-time monitoring and alerting systems (like Prometheus and Grafana).\nfamiliarity with Go, Python, or other OOP languages.\nfamiliarity with distributed caching frameworks such as Redis/Aerospike.\n\n\n\n\nGood to have\n\nat least five years of experience in the field of distributed microservices with high throughput, low latency, and integration, such as WS/REST.\nextensive background in machine learning system architecture design.\nUnderstanding of testing frameworks",
    "companyName": "Harvey Nash Poland ",
    "jobLocation": " Warsaw, Mazowieckie, Poland",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOPS | 4 TO 12 YEARS | PAN INDIA",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-4-to-12-years-pan-india-at-capgemini-3942633507?position=3&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=%2FUuiqFdDHg3JmPTVlY6mZA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Job Description\n\n\nLead MLOps initiatives, collaborating with key stakeholders to strategize, plan, and deliver projects\nDesign, develop, and deploy complex AI/ML solutions on cloud infrastructure, ensuring scalability for changing business and technical needs\nCreate infrastructure and architecture diagrams for projects\nProject manage, allocate tasks to junior ML engineers, and ensure project closure\nEnhance coding practices, conduct code reviews, and implement best practices for model management\nProvide thought leadership on new technologies, tools, and suggest improvements\nSupport the interview process for hiring both junior and senior ML engineers\nSpecialize in the deployment, monitoring, and maintenance of AI models in production\nCollaborate with governance lead and data scientists to institutionalize best practices\nBuild deployment pipelines, implement automation, and specialize in containerization and orchestration (e.g., Docker, Kubernetes)\nImplement continuous integration and continuous deployment (CI/CD) for efficient workflows\nFocus on scalability and resource management\n\n\nPrimary Skills\n\n\nMLOps Cloud Infrastructure\nML Engineering &ML Ops workflows & tools\nDeployment, Monitoring, and Maintenance of AI Models\nDeployment Pipelines,Automation\nContainerization (e.g., Docker)\nOrchestration (e.g., Kubernetes)\n\n\nSecondary Skills\n\n\nExpertise in specific cloud platforms (e.g., AWS Sagemaker, Azure, Google Cloud)\nExperience with specific programming languages (e.g., Python, R)\nUnderstanding of data governance and compliance\nBackground in software development practices\nExperience with version control systems (e.g., Git)\nProficiency in scripting languages for automation\nUnderstanding of DevOps principles and practices",
    "companyName": "Capgemini ",
    "jobLocation": " Bengaluru, Karnataka, India",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOps Engineer - Remote EU",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-remote-eu-at-understanding-recruitment-3958843107?position=4&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=H2WIwbIxtrjZTfSyHz%2Bw3g%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "MLOps Engineer (Remote)\n\nJoin our rapidly growing start-up dedicated to making the internet safer with cutting-edge AI technology �?.\n\nWe have VC funding from top investors and are analyzing millions of images and videos daily ??.\n\nAbout The Role\n\n\nBuild and operate our new ML platform ??\nDesign and manage Delta Lake transformations\nOptimize ML deployment APIs\nCollaborate to integrate models into production\nEnsure AI services' reliability and performance\n\n\nAbout You\n\n\nProactive ML expert with strong Python and Data Engineering skills ????\nExperience with ML pipelines, data architectures, and K8s deployment\nSkilled in creating inference/training pipelines\nCollaborative, ready to lead change, solve challenges, and set new standards\n\n\nPreferred\n\n\nRemote team and start-up experience\nCI/CD, SQL/NoSQL, Terraform, LLMs, and Apache Spark knowledge\n\n\nLocation: Remote, with quarterly travel to London ??, within 3-4 hours of UK time zone.\n\nReady to make a difference? Apply now! ??",
    "companyName": "Understanding Recruitment ",
    "jobLocation": " Oxford, England, United Kingdom",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "Data Engineer MLOPS/AI Engineer",
    "applicationLink": "https://nl.linkedin.com/jobs/view/data-engineer-mlops-ai-engineer-at-capgemini-3964924833?position=5&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=7Zy0OigiOMx6%2F9yhA%2F9aKA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Blue Harvest is a rapidly growing international software consultancy company that strives to provide first-rate engineers with both excellent technical abilities and soft skills.\n\nAt Blue Harvest, we believe that people can improve the world through the power of technology. We do this by creating a nurturing environment that promotes growth and creative thinking.\n\nWe enable our engineers and customers with innovative solutions to address some of the most challenging problems out there.\n\n\nYou have a passion for innovation and know-how to use your engineering skills to give our clients a solid lead in the digital world. You will work in multidisciplinary teams on innovative solutions.\nYou advise and support clients both during the initial scoping and pre-sales cycle as well as the implementation of proposed solutions and post-sales engineering activities.\nYou are going to ingest and process the raw data of several large international corporations. Next to that you will lead teams and create reusable data solutions.\nYou will be exposed to large volumes of data and related processing workloads. And of course a lot of customer contact in which you advise them on how to maximize the value of their data.\nYou will contribute to Blue Harvest's vision and help us build our data innovation portfolio;\nYou will be part of a culture with a high bar of engineering and emotional intelligence standards where development paths are self-determined within a mentor-led environment to support and guide these growth opportunities.\n\n\nYou will become part of Blue Harvest and join our Engineering Teams with different knowledge and varying levels of experience in the field. Everyone is passionate about Technology and the challenge that working within financial services offers.\n\nOf course, you will get a competitive salary with other interesting benefits. But more importantly, you will work at a fantastic and pleasant place where you can do more than just engineering. You will be learning, developing yourself, organizing events and speaking at conferences. And you will have the best Friday afternoon beers in our office in Utrecht.\n\nDo you have any further questions about this job? Get in contact with your recruiter, Maarten di Pietro.",
    "companyName": "Capgemini ",
    "jobLocation": " Utrecht, Utrecht, Netherlands",
    "jobPostDate": "2 days ago "
  },
  {
    "jobTitle": "MLOps Engineer (all genders)",
    "applicationLink": "https://de.linkedin.com/jobs/view/mlops-engineer-all-genders-at-understand-ai-3941262235?position=6&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=%2FGgVyIoFf%2Ftxe99wsCXVqQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Keywords\n\nMLOps | Cloud | Kubernetes\n\nThe role\n\nAs a MLOps-engineer at UAI, you enable the machine learning engineers to build, operate and ship models and to manage data in an efficient way. Having teams that are responsible for a product end to end, you will work in a team of machine learning engineers and collaborate closely with our DevOps experts across teams.\n\nThe role is a blend of system and software engineering where coding and automation are essential. Furthermore you can drive the implementation of particular solutions and distribute your knowledge to the other team-members. You embody the philosophies of DevOps with a greater focus on measuring and achieving reliability through engineering and operations work.\n\nYour tasks\n\n\nBuild and maintain the next generation of our ML infrastructure catering for...\nModel development\nData management\nModel operation and management and monitoring\nCost transparency\n\nProvide developer friendly tools to enable ML engineers\nDrive the implementation together with ML engineers\nCollaborate closely with our DevOps experts\nPromote MLOps mindset in the team\nConstantly evaluate state of the art MLOps solutions for our use case\nIdentify automation opportunities to gain efficiency, reliability, and scalability\n\n\nWhat will you need to be successful?\n\n\nExperience with MLOps tools\nStrong experience with at least one cloud provider – we are using Google Cloud\nExperience with Kubernetes\nAt least basic understanding of machine learning\nSolid experience in one high-level language, e.g. Python, JavaScript, Java, or similar\nLarge-scale system design exposure, in-depth understanding of UNIX/Linux, network technology, and security practices\nAbility to lead initiatives and motivate people\nEnjoy working in a team and actively communicating with your colleagues\nEducation, job experience, and special requirements\nUniversity degree in Computer Science (or related) or a proven track record as a MLOps expert\nGood communication skills in English both verbal and written\n\n\n\nWhat we offer\n\n\nA crucial role in a dynamic and fast-growing team\nA work environment that fosters trust, respect, and feedback\nAn onboarding buddy to integrate you smoothly into our team\nProductivity and improvement time between the development sprints\nA mentor helping you with your personal goals, technical progress in general and your software engineering skills in particular\nFree snacks, drinks, and the option to join activities like hiking, inline-skating, climbing or board game nights\nCompetitive salary, flexible working hours, work from home\n\n\n\nOverview of our tech stack\n\nGoogle Cloud, Kubernetes, Terraform, ArgoCD, Docker, Python, Typescript\n\nContact person\n\nKatrin Maar\n\nHR Business Partner\n\n+4917660199870",
    "companyName": "understand.ai ",
    "jobLocation": " Germany",
    "jobPostDate": "1 month ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://www.linkedin.com/jobs/view/mlops-engineer-at-clarifai-3953818552?position=7&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=9KFCjuw%2Bwx%2BoteE0POG0yQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "About the Company\n\nClarifai is a leading, full-lifecycle deep learning AI platform for computer vision, natural language processing, and audio recognition. We help organizations transform unstructured images, video, text, and audio data into structured data at a significantly faster and more accurate rate than humans would be able to do on their own. Founded in 2013 by Matt Zeiler, Ph.D. Clarifai has been a market leader in AI since winning the top five places in image classification at the 2013 ImageNet Challenge. Clarifai continues to grow with employees remotely based throughout the United States, Canada, Estonia, Argentina & India.\n\nWe have raised $100M in funding to date, with $60M coming from our most recent Series C, and are backed by industry leaders like Menlo Ventures, Union Square Ventures, Lux Capital, New Enterprise Associates, LDV Capital, Corazon Capital, Google Ventures, NVIDIA, Qualcomm and Osage.\n\nClarifai is proud to be an equal opportunity workplace dedicated to pursuing, hiring, and retaining a diverse workforce.\n\nThe Opportunity\n\nNote: We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas for this particular opportunity, as we are looking for someone who is eligible for a Secret or Top Secret Clearance.\n\nJoin our high-velocity, talented AI research and software engineering teams to build innovative Applied Computer Vision and Enterprise AI solutions addressing critical public sector problems. You will maintain data ingestion and model development pipelines with a strong focus on detail and testing, deploy cutting-edge AI algorithms into production, and build and maintain efficient pipeline tooling. This role allows you to make a significant impact on both the company and the broader AI field by solving challenging customer problems and integrating real-world ML Ops pipelines into the Clarifai platform.\n\nKey Responsibilities:\n\n\nCollaborate with scientists and engineers to enhance object detection, segmentation, tracking, and visual search capabilities and develop new products.\nDeploy production-ready models to customers and iteratively improve them based on feedback.\nMaintain our research ML infrastructure.\nTransition research projects from proof of concept to production.\nIntegrate your work directly into Clarifai's AI orchestration platform\n\n\nImpact\n\nYou will drive customer acquisition and revenue growth, working closely with various teams across the company, including research, backend, infrastructure, product, frontend, and design. This role offers a unique opportunity to make a substantial impact on the company and the AI industry.\n\nRequirements\n\n\n3+ years of experience with Python, focusing on Machine Learning or Computer Vision (PyTorch/TensorFlow).\nStrong MLOps philosophy and experience with associated tooling (Git, CI/CD, Docker, Kubernetes, Kubeflow, Hydra).\nExperience building and maintaining CI/CD pipelines with an emphasis on DevOps best practices.\n3+ experience with large scale software development: testing, automation, system-design, performance optimization, concurrent development\n3+ years of cloud exposure: AWS, Google Cloud, Azure (at least one of them)\nComfortable working in a shell environment.\nExperience working with complex existing codebases.\nEligible to obtain a U.S. Secret Security Clearance (U.S. Citizenship)\n\n\nGreat to Have\n\n\nExperience in object detection and tracking.\nExperience with model export (Torchscript, TensorRT).\nExperience with Golang, relational databases.\n\n\nThe salary hiring range for this position is $125,000 - $175,000 and flexible depending on relevant experience.",
    "companyName": "Clarifai ",
    "jobLocation": " Washington, DC",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-at-causaly-3964349530?position=8&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=KD7%2BeWzfCXSTl%2BtVKdL%2FHw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "About Us\n\nFounded in 2018, Causaly accelerates how humans acquire knowledge and develop insights in Biomedicine. Our production-grade generative AI platform for research insights and knowledge automation enables thousands of scientists to discover evidence from millions of academic publications, clinical trials, regulatory documents, patents and other data sources... in minutes.\n\nWe work with some of the world's largest biopharma companies and institutions on use cases spanning Drug Discovery, Safety and Competitive Intelligence. You can read more about how we accelerate knowledge acquisition and improve decision making in our blog posts here: Blog - Causaly\n\nWe are backed by top VCs including ICONIQ, Index Ventures, Pentech and Marathon.\n\nAbout the role:\n\nThe ML Ops Engineer will be responsible for designing, developing, and maintaining the infrastructure and tools that support our machine learning models. You will work closely with our data scientists, engineers, and product teams to ensure the smooth operation of our ML workflows, from data ingestion to model deployment.\n\nResponsibilities:\n\n\nDesign, implement, and maintain our ML infrastructure, including data pipelines, model training, and deployment workflows\nDevelop and maintain tools for automating ML workflows, such as data pre-processing, feature engineering, and model evaluation\nCollaborate with stakeholders to optimize model performance, scalability, and reliability in production, including monitoring, logging, and troubleshooting\nDevelop and maintain data quality checks and data validation pipelines\nImplement and maintain data versioning and data lineage tracking\nStay up-to-date with the latest developments in ML Ops and recommend best practices and new technologies to the team\n\n\n\nRequirements\n\n\nBachelor's or Master's degree in Computer Science, Engineering, or a related field\nApplied industry experience in MLOps, DevOps, or a related field\nExcellent programming skills in Python, with experience in ML frameworks\nExperience with containerization\nExperience with data pipelines, data warehousing, and ETL processes\nExperience with data versioning and data lineage tracking\nStrong understanding of ML model deployment, scaling, and management\nExcellent problem-solving skills, with the ability to debug complex issues\nStrong communication and collaboration skills, with the ability to work with cross-functional teams\nExperience with agile development methodologies and version control systems such as Git\n\n\nPreferred Qualifications:\n\n\nExperience with MLOps platforms such as MLflow, TensorFlow Extended (TFX), or Kubeflow\nExperience with DevOps tools such as Jenkins, GitLab CI/CD, or CircleCI\nExperience with BigQuery\n\n\n\nBenefits\n\n\nCompetitive compensation package\nPrivate medical insurance (underwritten on a medical health disregarded basis)\nLife insurance (4 x salary)\nIndividual training/development budget through Learnerbly\nIndividual wellbeing budget through Juno\n25 days holiday plus public holidays and 1 day birthday leave per year\nHybrid working (home + office)\nPotential to have real impact and accelerated career growth as an early member of a multinational team that's building a transformative knowledge product\n\n\nBe yourself at Causaly... Difference is valued. Everyone belongs.\n\nDiversity. Equity. Inclusion. They are more than words at Causaly. It's how we work together. It's how we build teams. It's how we grow leaders. It's what we nurture and celebrate. It's what helps us innovate. It's what helps us connect with the customers and communities we serve.\n\nWe are on a mission to accelerate scientific breakthroughs for ALL humankind, and we are proud to be an equal opportunity employer. We welcome applications from all backgrounds and fairly consider qualified candidates without regard to race, ethnic or national origin, gender, gender identity or expression, sexual orientation, disability, neurodiversity, genetics, age, religion or belief, marital/civil partnership status, domestic / family status, veteran status or any other difference.",
    "companyName": "Causaly ",
    "jobLocation": " London, England, United Kingdom",
    "jobPostDate": "3 weeks ago "
  },
  {
    "jobTitle": "MLops - Data Engineer",
    "applicationLink": "https://pt.linkedin.com/jobs/view/mlops-data-engineer-at-kcs-it-3952579345?position=9&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=ZBoFHQuuzlyUYialkFtfKQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "We’re looking for the special, unique and amazing YOU!\n\n@ KCS IT, we look for the ones that stands out, for those that always wants to be better and fight for it, and for those who has the same values that we do: dedication, energy, integrity, transparency, flexibility, trust, honesty, hard work, proactivity, team work.\n\nAt KCS we stand for equality and value diversity. We create a safe, diverse environment where opportunities are equal for everyone! We do not discriminate based on age, ethnicity, sexual orientation, gender, disability or any factor other than merit. All applications with skills for the position are welcome!\n\n\n\n\nWe are looking for an Amazing: Data Engineer - midSénior\n\n\n\n\nThe amazing you, will have:\n\nBachelor's and/or master's degree in Computer Science, Computer Engineering or similar;\nAt least 3 years of experience with machine learning;\nExperience with AWS Lambda/sagemarker/SQS;\nKnowledge of python, pandas, CICD and IaaC would be nice;\nFluent in English and Portuguese;\nGood communication and interpersonal skills;\nBe already in Portugal legally.\n\n\n\n\nWhy should you become part of our family?\n\nYou can develop a career that fits you: your career development is personalized, taking in consideration your needs and goals from a short to long term\nInteresting Challenges Ahead: you can work for several clients from different sectors of activity\nFree training programs: Our training and certification programs in languages, tech, behavior and business will help you to reach your full potential faster\nInternational projects in Benelux: you can gain international experience in Benelux and balance a new way of living with work\nType of projects (depending on the project you might find one of this types of projects):\nIn hybrid Systems: Is important to balance work with socialization, that´s why a hybrid system works for us and for you\nFull Remote projects: If you want to work while you enjoy the comfort of your home\nFull Onsite projects: if you prefere the company of your colleagues!\nTake care of your well-being: Enjoy our free nutrition, psicologist, general medicine appointments and our yoga and personal training days… all remote!\n\n\n\n\n\n\n\nWho are we?\n\nFounded in 2008 and based in Lisbon, KCS IT is a consulting company in the field of Information Technology and Services, focused on creating value for our clients through three main areas: Consulting, Outsourcing, Inovation and Training. Our commitment to talent development is unmistakable in the recent opening of the Porto, Leiria and Azores hubs, which aims to develop technology for the national and international market. Since 2018 we have been electedWe believe transparency, trust and integrity are the pillars of any business and relationship and that is what we promise our clients and employees who join our company KCS IT.\n\n\n\n\nHere, you can be totally sure about this: we value each person that joins us. We welcome everyone as part of this family and we do everything we can so that we can learn and grow together.",
    "companyName": "KCS iT ",
    "jobLocation": " Portugal",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://www.linkedin.com/jobs/view/mlops-engineer-at-remobi-3967691395?position=10&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=JDT1x9%2B0i%2Fq111p5S84xlg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "About us:\n\n\n\n\nWe are Remobi and we are passionate about connecting the world’s best technologists with the world’s most rewarding projects, regardless of borders. We build high performing, high quality, REMOTE technology teams. We are the experts in remote workforce mobilisation, we are Remobi.\n\n\n\n\nAbout the role:\n\nDuration: 6 months (with possibility to extend)\n\nLocation: Remote\n\nProject Language: English\n\n\n\n\nAs an MLOps Engineer, you will be responsible for designing, implementing, and maintaining scalable machine learning infrastructure.\n\n\n\n\nYou will work closely with data scientists, software engineers, and IT teams to ensure seamless integration and deployment of machine learning models.\n\n\n\n\nYour expertise in Python, AWS, Azure, Kubeflow, and Mlflow will be crucial in optimizing our ML workflows and ensuring robust model management and deployment.\n\n\n\n\nKey Responsibilities:\n\nDesign and implement scalable and efficient machine learning pipelines using Kubeflow and Mlflow.\nDevelop, deploy, and maintain ML models on cloud platforms such as AWS and Azure.\nCollaborate with data scientists to streamline model development and deployment processes.\nAutomate model training, testing, and deployment workflows.\nMonitor and optimize the performance of ML models in production.\nEnsure the security, reliability, and scalability of ML infrastructure.\nDevelop and maintain comprehensive documentation for ML workflows and systems.\nStay updated with the latest developments in MLOps practices and technologies.\n\n\n\n\nRequirements:\n\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nProven experience as an MLOps Engineer or similar role.\nStrong proficiency in Python and relevant libraries (e.g., TensorFlow, PyTorch, scikit-learn).\nHands-on experience with cloud platforms, particularly AWS and Azure.\nExpertise in containerization and orchestration tools such as Docker and Kubernetes.\nIn-depth knowledge of Kubeflow and MLflow for managing ML workflows.\nExperience with CI/CD pipelines and tools (e.g., Jenkins, GitLab CI).\nFamiliarity with version control systems (e.g., Git).\nExcellent problem-solving skills and attention to detail.\nStrong communication and collaboration skills.\n\n\n\n\nPreferred Qualifications:\n\nExperience with additional ML tools and frameworks (e.g., SageMaker, Databricks).\nUnderstanding of data engineering principles and tools (e.g., Spark, Kafka).\nExperience with monitoring and logging tools (e.g., Prometheus, Grafana).\nKnowledge of machine learning algorithms and model evaluation metrics.\nFamiliarity with agile methodologies and project management tools (e.g., Jira).",
    "companyName": "Remobi ",
    "jobLocation": " European Economic Area",
    "jobPostDate": "9 hours ago "
  },
  {
    "jobTitle": "MLOps",
    "applicationLink": "https://pl.linkedin.com/jobs/view/mlops-at-dcg-3968130015?position=11&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=6wCZDLFn8tCEQTL6t2Awvw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "RESPONSIBILITIES:\n\nManage Kubernetes (K8s) clusters on GCP\nConfigure and manage deployment charts\nOversee operators and nodes\nSet up Horizontal Pod Autoscaler\nDeploy pods using Machine Learning model images with Helm charts\nConfigure observability on the cluster\nWork with event-driven architectures, especially using GCP Pub/Sub\nCreate and improve data pipelines ensuring correct data ingestion to feature store\nPrepare infrastructure components deployments and manage consumers\nUnderstand the basics of data engineering, including differences between data warehouses and data lakes\nManage data lake components and create BigQuery instances as a DevOps\nBe willing to learn about feature stores and schema building\n\n\n\n\nREQUIREMENTS:\n\nMinimum 3 years of experience in a similar position\nProven hands-on experience with Kubernetes (K8s) on GCP\nAbility to configure and manage deployment charts, operators, and nodes\nExperience in setting up Horizontal Pod Autoscaler\nProficiency in deploying pods with machine-learning model images using Helm charts\nExperience in configuring observability tools for clusters\nExperience with event-driven architectures and GCP Pub/Sub\nAbility to create and enhance data pipelines ensuring correct data ingestion\nUnderstanding of data engineering basics, including data warehouse and data lake differences\nAbility to manage data lake components and create BigQuery instances\nStrong teamwork and communication skills\nWillingness to learn and adapt to new technologies, including feature stores and schema building\nEnglish level: B2-C2\nNice-to-have: understanding of feature stores and schema building\n\n\n\n\nOFFER:\n\nPrivate medical care\nCo-financing for the sport card\nTraining & learning opportunities\nConstant support of dedicated consultant\nTeam-building events organized by DCG\nEmployee referral program",
    "companyName": "DCG ",
    "jobLocation": " Poland",
    "jobPostDate": "12 hours ago "
  },
  {
    "jobTitle": "Data and MLOps Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/data-and-mlops-engineer-at-continental-3964459912?position=12&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=AZOqEX3xMz0C88Fe0NKZSQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Job Description:\n\nWork with Data Scientists, Machine Learning experts and Business stakeholders to design cloud-based, highly available Data Infrastructure for AI Workload.\nDesign the architecture of and implement cloud-based Data infrastructure / ETL pipelines according to best practices.\nProactively identify and automate manual data processes\nImplement release processes, workflows, and live deployments in complex IT environments\nEnsuring Post-release application stability and conducting post-mortem of failed routines\nImplement processes for Continuous integration, Test automation and Deployment (CI/CD Pipelines)\nSupporting prototyping activities and driving minimum viable products (MVP)\nUnderstand and translate business and application specific needs into technical requirements\nConsolidating complex data environments consisting of multiple data sources and formats\nProvide quality documentation of your design (process and workflows) and implementation including experiment tracking / logs.\nTake responsibility of end-to-end development of a module, work independently and where required take initiative to collaborate.\n\n\n\n\nQualification:\n\nAcademic Degree in Informatics, Computer Science or comparable qualification\nStrong programming experience with Python or CPP.\nProject based practical experience of working with Amazon Web Services (AWS) technologies.\nPractical experience based on previous projects with continuous integration, continuous deployment and test automation in architectures (eg. Jenkins, GitHub Actions).\nProject based hands-on experience of container and DevOps technologies such as Git, Docker, Kubernetes, KubeFlow\nExperience with data analytics tools such as Power BI or Tableau.\nSQL, NoSQL\nNice to have: Hadoop, Spark, Spark Streaming, Presto, Hive, Crontab, Airflow\nExperience in Agile development methods (Scrum, Kanban)\nExcellent communication skills and capability to present technological concepts coherently to the business and innovation process",
    "companyName": "Continental ",
    "jobLocation": " Bengaluru, Karnataka, India",
    "jobPostDate": "1 day ago "
  },
  {
    "jobTitle": "MLOps Engineer(NJ)",
    "applicationLink": "https://www.linkedin.com/jobs/view/mlops-engineer-nj-at-tiger-analytics-3719415004?position=13&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=D3ID7gC6m6jxD7f4LdFT3A%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Tiger Analytics is looking for experienced Machine Learning Engineers to join our fast-growing advanced analytics consulting firm. Our employees bring deep expertise in Machine Learning, Data Science, and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner.\n\nWe are looking for top-notch talent as we continue to build the best global analytics consulting team in the world. You will be responsible for:\n\n\nML Engineer with 5-7 years of IT experience\nPipeline Training Models, Building, Deployment, Testing, and Monitoring using AWS SageMaker, AWS CFT, AWS CodePipeline, Lambda, etc\nDevelop Airflow DAGs to run training and scoring pipelines\nDevelop a Testing framework with Pytest\nImplement monitoring solution with homebrew solution using Lambda and Dash\nDevelop Data Quality solutions potentially leveraging Great Expectations\n\n\n\nRequirements\n\n\nBachelor's degree or higher in computer science or related, with 5+ years of work experience\nAbility to collaborate with Data Engineers and Data Scientists to build data and model pipelines and help run machine learning tests and experiments\nExperience in AWS - SageMaker (ProcessingJobs, TrainingModels, EndPoints)\nExperience in Lambda CloudFormation or Terraform Apache Airflow, Astronomer Docker\nKnowledge of traditional ML Models\nPython, Spark, Hadoop, and Docker with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design\nKnowledge of ML frameworks like Scikitlearn, Tensorflow, and Keras\nExperience in Pandas, sklearn, Numpy, Scipy\n\n\n\nAdditional Skills Required\n\n\nKnowledge of Database/Data Engineering\nExperience with Oracle, Spark, Hadoop, Athena, API, FastAPI, Flask, ReST\nKnowledge of MLflow, Airflow, and Kubernetes\nExperience with Cloud environments and knowledge of AWS Services, Service Catalog, SNS, SES\n\n\n\nBenefits\n\nThis position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",
    "companyName": "Tiger Analytics ",
    "jobLocation": " New Jersey, United States",
    "jobPostDate": "9 months ago "
  },
  {
    "jobTitle": "Senior MLOps Engineer",
    "applicationLink": "https://pl.linkedin.com/jobs/view/senior-mlops-engineer-at-exposit-3953227507?position=14&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=E%2BR0tMFibLlmY%2BSpOb%2FCcQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "We are looking for a skilled MLOps Engineer with experience in AWS and/or Azure, recent foundation models, and state-of-the-art (SOTA) machine learning technologies, particularly in Computer Vision, NLP problems, and Retrieval-Augmented Generation (RAG).\n\n\n\n\nKey Responsibilities\n\n- Design, develop, and maintain ML pipelines and infrastructure using cloud solutions.\n\n- Collaborate with data scientists and developers to align ML solutions with business goals.\n\n- Consult clients on migrating to more advanced MLOps approaches.\n\n\n\n\nRequired Qualifications\n\n- 5+ years of experience in ML projects.\n\n- Experience with Azure ML services and/or AWS SageMaker.\n\n- Experience with foundation models (e.g. GPT, Cohere, Llama, Stable Diffusion) and ML frameworks (e.g., TensorFlow, PyTorch).\n\n- Expertise in CV, NLP problems, and RAG.\n\n- Proficiency in Python programming language.\n\n- Experience with containerization (Docker) and data workflow orchestration (Apache Airflow or Google Cloud Composer).\n\n- Knowledge of at least two of the following CI/CD tools: Jenkins, GitHub Actions, GitLab CI/CD, Azure DevOps.\n\n- Familiarity with data versioning and experiment tracking tools (DVC, MLflow, or similar).\n\n\n\n\nNice to Have\n\n- ML consulting experience.\n\n- AI architecture design experience.\n\n- Experience with Amazon Bedrock agents.\n\n- Knowledge of big data technologies (Apache Spark, Databricks, Snowflake, or Amazon Kinesis).\n\n- Certifications in Azure and/or AWS.",
    "companyName": "Exposit ",
    "jobLocation": " Poland",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "MLOps Engineer (m/f/d)",
    "applicationLink": "https://pt.linkedin.com/jobs/view/mlops-engineer-m-f-d-at-walaris-3933435819?position=15&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=AAHhXpbhKNn4sUVqTXWmyg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Founded at Stanford University, Walaris develops autonomous AI-based solutions focused on enhancing situational awareness. Our AirScout software platform uses artificial intelligence, sensor fusion, and edge computing to detect threats in the air, on sea or on the ground. Our cutting-edge technology is utilized by commercial, government, and military users to increase situational awareness in and around sensitive locations.\n\nWe are seeking a talented MLOps Engineer to join our dynamic team and play a key role in designing and implementing robust MLOps pipelines, and optimizing ML models for real-world impact.\n\nKey Responsibilities{{:}}\n\n\nBuilding data ingestion and MLOps pipelines{{:}} Utilize tools like Kubeflow, MLFlow, DataRobot, Airflow, Docker, and Kubernetes to streamline model development and deployment\nOrchestrate CI/CD pipelines{{:}} Collaborate with DevOps teams to automate the continuousintegration and delivery process using GitLab CI or similar tools\nMachine learning model optimization{{:}} Review, refactor, and optimize machine learning models forimproved performance, scalability, and eﬃciency\nContainerization and deployment{{:}} Containerize machine learning models and orchestrate theirdeployment, versioning, and monitoring\nModel testing and validation{{:}} Develop and automate tests to ensure the quality and reliability ofmachine learning models\nCollaboration and documentation{{:}} Work closely with cross-functional teams, including datascientists, data engineers, and architects. Document processes and best practices\n\n\n\nRequirements\n\n\n\nRequired Qualiﬁcations{{:}}\n\nBachelor's degree in computer science, software engineering, or a similar discipline\nProﬁciency with MLOps frameworks such as Kubeﬂow, MLFlow, DataRobot, and Airﬂow\nFamiliarity with Docker and Kubernetes, and experience with container orchestration\nStrong programming skills in Python and Bash. A solid understanding of Linux environments\nKnowledge of popular machine learning frameworks such as PyTorch, TensorFlow, Keras, andscikit-learn\nExperience with software development and test automation\nFluent in English with excellent communication skills\n\n\nDesired Qualifications{{:}}\n\n\nMaster's degree in in computer science, software engineering, or a similar discipline\nExperience in computer vision field and large-scale visual data management\nExperience in using AWS, Microsoft Azure, or Google Cloud Platform services is a plus\nExperience with CI/CD tools such as Jenkins is appreciated\n\n\n\nBenefits\n\n\n\nJoin our mission and our dynamic team! Help save lives and protect local and national security using bleeding edge technologies. This opportunity provides the chance to pioneer new fields and shoulder significant responsibility developing and deploying industry-defining solutions. At Walaris, you'll have creative freedom, receive competitive compensation, and work in a fast-paced environment.\n\nIf you're interested in learning more, please submit an application via our online application form.\n",
    "companyName": "Walaris ",
    "jobLocation": " Lisboa, Lisbon, Portugal",
    "jobPostDate": "2 months ago "
  },
  {
    "jobTitle": "MLOps Developer ",
    "applicationLink": "https://www.linkedin.com/jobs/view/mlops-developer%C2%A0-at-software-technology-inc-3792378653?position=16&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=BzKWWsFHHDUh98L%2BrOiLQQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Role: MLOps Developer\n\nPosition: Remote\n\nDuration :LongTerm\n\nNotes: Candidate must be willing to be part of on-call rotation.\n\nYour Future Duties And Responsibilities\n\nMonitoring - Actively monitor ML jobs through logging, metrics, and alerts.\n\nIncident Management Address job failures. Rerun jobs, maintain model/job versions in production.\n\nInfrastructure Scalability - Scale infrastructure to handle production workloads. Tuning, capacity planning, cost optimization.\n\nCompliance and Security - Apply security best practices. Encrypt data, manage secrets, enforce access controls.\n\nTechnical Support - Troubleshoot integration and infrastructure issues.\n\nOperations Review Monthly Incident management summary, Change management summary and other support metrics.\n\nModel Re-training - Schedule regular retraining of models on new data. Manage code and config changes needed for retraining.\n\nModel Evaluation - Continuously evaluate model performance on test data. Watch for statistical validation issues.\n\nData Validation - Monitor production data inputs. Check for statistical changes, missing values, outliers, errors.\n\nDependency Management - Manage libraries, frameworks, ML pipelines. Keep versions aligned across dev, test, prod environments.\n\nUpdate Python package versions for Airflow and Lambda if libraries become deprecated and other components and services as needed to customize the environment.\n\nDevOps Use version control, Infrastructure as Code, and Configuration Management tools to develop automation which deploys code base.\n\nAutomation Programmatically define repeatable and reliable tasks which reduce operational overhead.\n\nTesting programmatically enforcing quality standards related to the application, automation, and underlying ml models.\n\nRequired Qualifications To Be Successful In This Role\n\nRequirements: 3-7 years of proven experience in the following areas:\n\nCloud\n\nAWS CLI\n\nAWS SDK (boto3)\n\nParameter store & Secrets Manager\n\nLambda\n\nData Engineering\n\nSQL (Ability to write, Debug, and optimize queries)\n\nDynamoDB\n\nRedshift\n\nProgramming: IDE (VS Code / PyCharm),\n\nTesting (unit test/pytest/mock)\n\nPython\n\nMachine Learning\n\nML Development (Sage Maker)\n\nML Programming (Pandas, NumPy, Scikit Learn, Matplotlib, lightgbm)\n\nModeling\n\nDevOps\n\nGeneral Linux Terminal (ps, awk, grep, netstat, etc.)\n\nShell Scripting (BASH)\n\nYAML, IaC (Terraform, Cloud Formation)\n\nCI/CD (Code Build, Code Deploy)\n\nOrchestration (Apache Airflow)\n\nContainerization (Docker, Kubernetes)\n\nThanks & Regards\n\nMohan sai\n\nTechnical recruiter\n\nPhone# +1-619-605-0324|mohan.sai@stiorg.com\n\nSoftware Technology, Inc\n\nwww.stiorg.com",
    "companyName": "Software Technology Inc. ",
    "jobLocation": " United States",
    "jobPostDate": "6 months ago "
  },
  {
    "jobTitle": "MLOps",
    "applicationLink": "https://pl.linkedin.com/jobs/view/mlops-at-it-lumier-3776770872?position=17&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=x5wGIpJ94yzU8IWFJkv0cw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Who we are?\n\nIT Lumier is a new company with international reach specializing in IT HR Consulting and IT Outsourcing. We come from large, established HR and IT companies, but we represent a fresh perspective and new quality in this rapidly changing market. Join our elite and experienced Lumiers team. You will have the opportunity to participate in many interesting projects becoming part of a global community of IT experts.\n\nOur Client is a market leader in the E-Commerce industry, operating globally. We are looking Site Reliability Engineer, who will join to the Team, and help develop the Project.\n\nJoin us, and we will make sure that the offer is tailored to your needs. We care about our Experts and want to ensure you will expand your skills, meet your financial expectations and develop in the professional field.\n\nRequirements\n\n\nBachelor's or higher degree in Computer Science, Engineering, or related field\n8+ years of experience in ML engineer or similar role\nGood understanding of ML and AI concepts. Hands-on experience in ML/AI model development.\nHands-on experience with containerization (using Kubernetes, Docker)\nExperience in operationalizing Data Science projects (MLOps) using at least one of the popular - frameworks or platforms (e.g. Kubeflow & AWS Sagemaker).\nProficiency in Python used both for ML and automation tasks.\nGood knowledge of Bash and Unix command line toolkit.\nExperience in CI/CD/CT\n\n\nNice To Have Qualifications\n\n\nCertification in relevant techniques (e.g. AWS Certified Machine Learning Specialty)\n\n\nAbout The Position\n\n\nBuild and deploy machine learning solutions into production\nCreating microservices for task-specific AI cloud services\nImplement solutions for monitoring model performance and triggering alerts.\nDesign and implement infrastructure for machine learning cloud services\nDevelop ML flow automation scripts\nResearch modern MLOps tools, frameworks and platforms\nWork on a backlog of activities to raise MLOps maturity in the organization.\nProactively introduce a modern, agile and automated approach to Data Science.\nConduct internal training and presentations about the benefits and usage of MLOps tools.\n\n\nPlease send your CV by clicking APPLY. We are happy to answer your questions and talk to you about this project.",
    "companyName": "IT Lumier ",
    "jobLocation": " Warsaw, Mazowieckie, Poland",
    "jobPostDate": "7 months ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-engineer%09%09%09%09%09%09%09-at-volkswagen-group-technology-solutions-india-3964996041?position=18&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=S9tqqVEw8%2B%2Byu%2Fd4Y%2B80Lw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "MLOps Engineer\n\nExperience: 7 years to 10 years\n\nJob Location : Pune and Bangalore\n\n\n\n\nRole\n\nWe are seeking a highly skilled MLOps Engineer to join our growing team and play a critical role in building and deploying our next-generation Artificial Intelligence and Machine Learning (AIML) solutions on the cloud. You will be responsible for bridging the gap between development and operations, ensuring a smooth transition of machine learning models from experimentation to production. With your expertise in MLOps practices and cloud technologies, you will build and maintain robust pipelines for training, testing, deploying, and monitoring AIML models at scale.\n\nResponsibilities\n\n- Design, develop, and implement automated MLOps pipelines for the entire AIML lifecycle (training, testing, deployment, monitoring) on cloud platforms (e.g., AWS, Azure, GCP).\n\n- Utilize CI/CD tools and practices to automate the build, test, and deployment of machine learning models.\n\n- Integrate MLOps pipelines with version control systems and data management solutions.\n\n- Develop and implement unit and integration tests for MLOps pipelines.\n\n- Configure and manage cloud infrastructure for efficient training and deployment of AIML models.\n\n- Monitor model performance in production, identify potential issues, and implement corrective actions.\n\n- Collaborate with data scientists, machine learning engineers, and DevOps teams to ensure seamless integration and operation of AIML solutions.\n\n- Stay up-to-date on the latest advancements in MLOps tools and cloud technologies relevant to AIML deployments.\n\n- Continuously improve MLOps processes and optimize the performance and efficiency of AIML pipelines.\n\n\n\n\n\n\n\n\n\n\nTechnical Skills required:\n\n- Minimum 5 years of experience in software engineering or a related field.\n\n- Strong understanding of Machine Learning concepts and the ML lifecycle.\n\n- Experience with MLOps tools and frameworks (e.g., Kubeflow, MLflow, Metaflow).\n\n- Experience with monitoring tools and techniques for ML models (e.g., Prometheus, Grafana).\n\n- Experience with specific AIML frameworks and libraries (e.g., TensorFlow, PyTorch, Scikit-learn).\n\n- Proficiency in cloud platforms (AWS, Azure, GCP) and their machine learning services (e.g., SageMaker, Azure Machine Learning, AI Platform).\n\n- Experience with CI/CD tools and methodologies (e.g., Git, Jenkins, GitLab CI/CD).\n\n- Experience with scripting languages (e.g., Python, Bash) and familiarity with containerization technologies (Docker, Kubernetes) is a plus.\n\n- Excellent problem-solving and analytical skills.\n\n- Strong communication and collaboration skills to work effectively with cross-functional teams.\n\n- Passion for building robust and scalable solutions for deploying AIML models.",
    "companyName": "Volkswagen Group Technology Solutions India ",
    "jobLocation": " Pune, Maharashtra, India",
    "jobPostDate": "20 hours ago "
  },
  {
    "jobTitle": "ML OPS Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/ml-ops-engineer-at-deloitte-3954339200?position=19&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=7akMOi0%2BazbbdrWo3vCpdw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "What impact will you make?\n\n\n\n\nEvery day, your work will make an impact that matters, while you thrive in a dynamic culture of inclusion, collaboration and high performance. As the undisputed leader in professional services, Deloitte is where you’ll find unrivaled opportunities to succeed and realize your full potential.\n\n\n\n\nDeloitte is where you’ll find unrivaled opportunities to succeed and realize your full potential.\n\n\n\n\nThe Team\n\nThe world of business, economics, and finance is rapidly changing. Trends in the economy affect businesses, industries, and the financial markets that interact with one another in dynamic and often unpredictable ways. The Deloitte Industry team is focused on analysing economic and industry developments in India and their relevance to businesses. The team is responsible for conducting path-breaking and innovative research, analyze trends, and develop in-depth business and industry/sector thought leaderships that provide useful insights to enable business teams/partners to make strategic decisions.\n\n\n\n\nCollaborating with cross-functional teams, including data scientists, software engineers, and DevOps specialists, you’ll ensure seamless integration of machine learning & AI models into our production environments.\n\nResponsibilities:\n\nSet up and maintain infrastructure on cloud platforms such as AWS and Azure for machine learning workloads.\nCollaborate with software engineers to integrate machine learning components into applications and services.\nCollaborate with DevOps teams to ensure efficient deployment and scaling of machine learning models.\nDesign and implement end-to-end machine learning pipelines, incorporating tools and services for data preprocessing, model training, and deployment.\nDevelop and maintain automated workflows for continuous integration and continuous deployment (CI/CD) of machine learning models.\nDeploy machine learning models into production environments and manage their lifecycle.\nImplement monitoring solutions to track model performance, data drift, and other relevant metrics.\nWork closely with data scientists to understand model requirements and assist in model development.\nStay updated on the latest advancements in MLOps tools and technologies and recommend improvements to existing workflows.\nIncorporate cloud cost management strategies, optimizing machine learning workloads for cost efficiency.\n\nRequired Skills and Qualifications:\n\nBachelor’s degree in computer science, computer applications, Engineering, or a related field.\nMinimum 7 years of full-stack software development experience, ideally in a SaaS or microservice-based system.\nStrong proficiency in cloud platforms, especially AWS.\nExperience with machine learning frameworks such as TensorFlow, PyTorch, or Scikit-learn.\nProficiency in the following technologies:\nFastAPI\nSelenium\nDocker\nAWS services (S3, Athena, EC2, ECR, ECS, AppRunner)\nReactJS\n\nPreferred Qualifications:\n\nMaster’s degree in a relevant field.\nExperience with MLops practices and deployment of machine learning applications.",
    "companyName": "Deloitte ",
    "jobLocation": " Bengaluru, Karnataka, India",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOps Engineer (all genders)",
    "applicationLink": "https://de.linkedin.com/jobs/view/mlops-engineer-all-genders-at-understand-ai-3911472056?position=20&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=wBxtYXsO3lT4nu7ok80o2w%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Keywords\n\nMLOps | Cloud | Kubernetes\n\nThe role\n\nAs a MLOps-engineer at UAI, you enable the machine learning engineers to build, operate and ship models and to manage data in an efficient way. Having teams that are responsible for a product end to end, you will work in a team of machine learning engineers and collaborate closely with our DevOps experts across teams.\n\nThe role is a blend of system and software engineering where coding and automation are essential. Furthermore you can drive the implementation of particular solutions and distribute your knowledge to the other team-members. You embody the philosophies of DevOps with a greater focus on measuring and achieving reliability through engineering and operations work.\n\nYour tasks\n\n\nBuild and maintain the next generation of our ML infrastructure catering for...\nModel development\nData management\nModel operation and management and monitoring\nCost transparency\nProvide developer friendly tools to enable ML engineers\nDrive the implementation together with ML engineers\nCollaborate closely with our DevOps experts\nPromote MLOps mindset in the team\nConstantly evaluate state of the art MLOps solutions for our use case\nIdentify automation opportunities to gain efficiency, reliability, and scalability\n\nWhat will you need to be successful?\n\n\nExperience with MLOps tools\nStrong experience with at least one cloud provider – we are using Google Cloud\nExperience with Kubernetes\nAt least basic understanding of machine learning\nSolid experience in one high-level language, e.g. Python, JavaScript, Java, or similar\nLarge-scale system design exposure, in-depth understanding of UNIX/Linux, network technology, and security practices\nAbility to lead initiatives and motivate people\nEnjoy working in a team and actively communicating with your colleagues\nEducation, job experience, and special requirements\nUniversity degree in Computer Science (or related) or a proven track record as a MLOps expert\nGood communication skills in English both verbal and written\n\n\nWhat we offer\n\n\nA crucial role in a dynamic and fast-growing team\nA work environment that fosters trust, respect, and feedback\nAn onboarding buddy to integrate you smoothly into our team\nProductivity and improvement time between the development sprints\nA mentor helping you with your personal goals, technical progress in general and your software engineering skills in particular\nFree snacks, drinks, and the option to join activities like hiking, inline-skating, climbing or board game nights\nCompetitive salary, flexible working hours, work from home\n\n\nOverview of our tech stack\n\nGoogle Cloud, Kubernetes, Terraform, ArgoCD, Docker, Python, Typescript\n\nContact person\n\nKatrin Maar\n\nHR Business Partner\n\nkatrin.maar@understand.ai\n\n+4917660199870\n\nAbout Us\n\nUnderstand.ai was founded in 2017 with the vision in mind to make AI accessible to everyone. To achieve this goal, we’re solving the data problem of AI. The tooling and services provided by understand.ai enable our customers to get the right data, at the right quality and right quantity, to make production-grade AI products a reality. Join us to become part of this journey!\n\nHeadquartered in Karlsruhe, our team has grown to more than 80 employees since 2017 and is part of the dSPACE Group since 2019. dSPACE is a market innovator and leader in providing solutions and systems for embedded controller software development in the Automotive, Aerospace, and Manufacturing industries. Founded in Germany in 1988, dSPACE employs over 2200 people worldwide, who are committed to making the embedded controls software development process more efficient through innovative tools and services.\n\nDue to our success in growing customer numbers and projects, we need to scale our structure and team sizes in order to continue providing excellent service. Our goal is to make our customers happy and our employees happy. We offer a variety of benefits, but more importantly, we offer an interesting & meaningful work environment and responsibilities, on which you can work with a great level of autonomy.\n\nWe can’t wait to see what kind of future you choose to build at UAI - so click on the “apply for this position” button and together create the gold standard for ground truth data for autonomous transportation!",
    "companyName": "understand.ai ",
    "jobLocation": " Karlsruhe, Baden-Württemberg, Germany",
    "jobPostDate": "2 months ago "
  },
  {
    "jobTitle": "MLOPS Engineer",
    "applicationLink": "https://www.linkedin.com/jobs/view/mlops-engineer-at-addsource-3929079753?position=21&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=bkq64nYs0tLE3eqhtDQ0QQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Key Responsibilities\n\n\nDesign, build, and maintain cloud infrastructure on AWS using tools such as CloudFormation and Terraform, following infrastructure as code principles, with a focus on establishing and maintaining best practices for MLOps infrastructure.\nManage and optimize AWS services such as AWS Sagemaker and AWS ECS.\nImplement security best practices and ensure compliance with industry standards.\nCollaborate with development teams to streamline the software development lifecycle.\nMonitor system performance and troubleshoot issues to ensure uptime and reliability.\nDesign and implement cloud network architecture, including VPCs, subnets, SGs, DNS, load balancers.\nImplement and manage CI/CD pipelines for automated deployment and testing.\n\n\nRequirements\n\n\nExtensive experience with AWS system and network architecture design, with specific focus on AWS Sagemaker and AWS ECS.\nStrong proficiency in CloudFormation and Terraform for infrastructure as code.\nProficiency in at least one programming language, with preference for Ruby.\nStrong problem-solving skills and the ability to troubleshoot complex issues.\nAWS Solutions Architect certifications (optional but preferred).\nExperience with infrastructure migration projects is a plus.\nExcellent communication and collaboration skills.\n\n\nEDUCATION\n\n\nBachelor’s degree in computer science or equivalent certifications.",
    "companyName": "AddSource ",
    "jobLocation": " United States",
    "jobPostDate": "2 months ago "
  },
  {
    "jobTitle": "Python MLOPS Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/python-mlops-engineer-at-virtusa-3966297990?position=22&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=XGB%2B5oaHNzhWSzUPwMQ9Iw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Role GDT WS\n\nPython MLOPS\n\nHadoop EngineerExp\n\n5+Location Pune/HyderabadRole DescriptionML Engineers who will contribute across the entire ecosystem, including Python batch processes, REST API design, and creation/improvements to CI/CD pipelines. Keys Skills RequiredStrong Python skills knowledge of any other object oriented language a plusFamiliarity with ML algorithms and principlesExperience with DevOps and CI/CD any JenkinsExperience working with Big Data technologies Hadoop, HDFS, Elasticsearch, SparkExperience working with Cloud ideally GCPStrong software engineering fundamentals git, code reviews, agile team working.Familiarity with Python REST API frameworks a plus Flask, Fast APIExperience in Docker Deployment and KubernetesExperience with Airflow used as orchestrator and scheduler.",
    "companyName": "Virtusa ",
    "jobLocation": " Pune, Maharashtra, India",
    "jobPostDate": "2 days ago "
  },
  {
    "jobTitle": "MLops Consultant",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-consultant-at-capgemini-3951407332?position=23&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=y45qQC7N6OkVjGJqHWmoSQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Position: MLops\n\nLocation: PAN India\n\n\n\n\nJob Summary:\n\nWe are searching for a highly skilled and experienced MLOps Consultant to join our growing team. In this role, you will play a pivotal role in ensuring the smooth transition of machine learning models from development to production. You will collaborate with data scientists, engineers, and business stakeholders to implement best practices for MLOps, optimize model performance, and ensure the ongoing success of our machine learning initiatives.\n\n\n\n\nResponsibilities:\n\nPartner with data scientists and engineers to understand the technical aspects of machine learning models.\nDesign and implement MLOps pipelines for training, deployment, monitoring, and serving of machine learning models.\nAutomate the machine learning lifecycle, including data versioning, model training, and deployment.\nSelect and implement appropriate tools and technologies for MLOps, such as version control systems, containerization technologies (Docker, Kubernetes), and monitoring tools (Prometheus, Grafana).\nDevelop and implement a comprehensive monitoring strategy for production ML models, including anomaly detection and performance metrics.\nCollaborate with DevOps teams to ensure seamless integration of MLOps pipelines with existing CI/CD workflows.\nContinuously improve MLOps processes to enhance efficiency, scalability, and reliability.\nStay up-to-date on the latest advancements in MLOps tools and methodologies.\nDocument MLOps processes and best practices.\nProvide guidance and support to data science and engineering teams on MLOps best practices.\nParticipate in code reviews for MLOps pipelines.\n\n\n\n\nQualifications:\n\nMaster's degree in Computer Science, Data Science, or a related field (or equivalent experience).\n3+ years of experience in a technical role related to machine learning or data science.\nProven experience in designing and implementing MLOps pipelines.\nStrong understanding of machine learning concepts and algorithms.\nExperience with cloud platforms (AWS, Azure, GCP) is a plus.\nFamiliarity with version control systems (Git) and containerization technologies (Docker, Kubernetes).\nExperience with MLOps tools (MLflow, Kubeflow, Metaflow) is a plus.\nExperience with monitoring tools (Prometheus, Grafana) is a plus.\nExcellent communication, collaboration, and problem-solving skills.\nAbility to work independently and as part of a team.\nStrong attention to detail and a commitment to quality.",
    "companyName": "Capgemini ",
    "jobLocation": " Bangalore Urban, Karnataka, India",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "MLOps engineer_Manju_Capgemini",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-engineer-manju-capgemini-at-codersbrain-3666993659?position=24&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=xJPHa%2BeLxmRxigZD0qUlQQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Location: Bangalore\n\nMandatory\n\n\nMinimum of 4 to 16 years of relevant work experience as MLOps engineer\nStrong hands on Experience in managing reproducible AI/ML CICD pipeline using AWS Sagemaker, Cloud formation, Kubernetes, docker\nWell-versed in data structures, data modelling, and database management systems, model onboarding, automated model training, model versioning and governance\nExperience in creating Infra as Service\nExperience in enterprise cloud setup\n\n\nGood To Have\n\n\nCertified AWS SageMaker\nAWS solution architect\nKnowledge of Medical domain ( Dicom,HL7, FHIR)",
    "companyName": "CodersBrain ",
    "jobLocation": " Pune, Maharashtra, India",
    "jobPostDate": "1 year ago "
  },
  {
    "jobTitle": "MLOps Engineer: ML Recall Team (Remote)",
    "applicationLink": "https://am.linkedin.com/jobs/view/mlops-engineer-ml-recall-team-remote-at-constructor-3847915374?position=25&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=OTj086cvDYAI9574DNUo2Q%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "About Us\n\nConstructor is the only search and product discovery platform tailor-made for enterprise ecommerce where conversions matter. Constructor's AI-first solutions make it easier for shoppers to discover products they want to buy and for ecommerce teams to deliver highly personalized experiences that drive impressive results. Optimizing specifically for ecommerce metrics like revenue, conversion rate and profit, Constructor generates consistent $10M+ lifts for some of the biggest brands in ecommerce, such as Sephora, Petco, home24, Maxeda Brands, Birkenstock and The Very Group. Constructor is a U.S. based company that was founded in 2015 by Eli Finkelshteyn and Dan McCormick. For more, visit: constructor.io.\n\nML recall team consistency deliver KPI lifts for our customers in search and make our DS part more transparent for our customers.\n\nChallenges you will tackle\n\n\nBuild, deploy, and support our search service including io-bound web services, cpu-bound services and data services\nWrite AWS CloudFormation scripts, Jenkins jobs, Bash scripts, and Github actions\nWork on system performance optimization (esp. in case of using large ML models)\nSet up service observability, monitoring metrics, and alerting (Prometheus, Grafana, PagerDuty, AWS CloudWatch)\nCollaborate with technical and non-technical business partners to develop / update search functionalities\nWork on ML improvements\n\n\nAbout you\n\n\nYou are excited about building performance ML platform and practical search systems for 200M+ requests per day\nYou are an excellent communicator\nYou love to work on performance optimization\n\n\n\nRequirements\n\n\nProficiency in Infrastructure as Code (IaC) tools like CloudFormation or Terraform for managing cloud resources\nPython knowledge\nFamiliarity with Service-Oriented Architecture, knowledge of communication protocols like protobuf & familiarity with networking principles\nHands-on experience with setting up and improving CI/CD pipelines (we're using Jenkins and Github Actions)\nProficiency with big data stack for end-to-end ML product development\nExperience in designing, developing & maintaining highload distributed real-time services\nExperience with cloud providers (any kind of, we're using AWS)\nExperience with NoSQL and relational databases and distributed systems\nExperience in server-side coding for web services, and a good understanding of API design principles\nWill be a huge plus\nExperience with Rust (or C/C++)\nStrong knowledge of data structures, algorithms and their trade-off\n\nSalary for this position 80-110k USD + stock options\n\nBenefits\n\n\nUnlimited vacation time: we strongly encourage all of our employees take at least 3 weeks per year\nA competitive compensation package including stock options\nCompany sponsored US health coverage (100% paid for employee)\nFully remote team - choose where you live\nWork from home stipend! We want you to have the resources you need to set up your home office\nApple laptops provided for new employees\nTraining and development budget for every employee, refreshed each year\nParental leave for qualified employees\nWork with smart people who will help you grow and make a meaningful impact\n\n\n\nDiversity, Equity, and Inclusion at Constructor\n\nAt Constructor.io we are committed to cultivating a work environment that is diverse, equitable, and inclusive. As an equal opportunity employer, we welcome individuals of all backgrounds and provide equal opportunities to all applicants regardless of their education, diversity of opinion, race, color, religion, gender, gender expression, sexual orientation, national origin, genetics, disability, age, veteran status or affiliation in any other protected group.",
    "companyName": "Constructor ",
    "jobLocation": " Yerevan, Yerevan, Armenia",
    "jobPostDate": "4 months ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://be.linkedin.com/jobs/view/mlops-engineer-at-radix-3789187567?position=26&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=Xrda2Bwu7hXK%2B8RbtJUT0g%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Artificial Intelligence isn't coming — it's already here, and it's changing everything.\n\nWelcome to Radix! ❤️ The heart of AI innovation nestled in Belgium, and your next potential playground! At Radix, we believe in AI as a co-pilot for people, helping them to do more and ultimately allowing us to be more human. We provide expert guidance and deliver AI solutions that have a positive impact on the world. 🌍\n\nToday our mission is to become the No. 1 in Europe in the area of AI consultancy.\n\nWhat you’ll do\n\nWith your talent, passion, and expertise, you’ll become part of an amazing team that makes the impossible possible! Next to that, you have an impact from the start & we will invest in your development to further your technical and personal growth. In this role, you’ll have the opportunity to work and learn, on impactful & rewarding challenges, including:\n\n\nDesigning and implementing Machine Learning Environments that make the life of ML engineers and data scientists at our clients, but also internally, better\nContinuously building and deploying reproducible and scalable solutions on cloud infrastructure\nImplement versioning of machine learning datasets, models and tracking of experiments\nDesign and build continuous integration of AI applications\nSet up the monitoring and tracing tools in order to easily maintain our solutions\n\n\n\nWhich clients will you be working for?\n\nAll our clients are chosen with respect to our values and beliefs at Radix. Therefore, we offer you the opportunity to join one of the leading AI solution providers and work together with a breadth of industries and like-minded organizations, including GSK, Brussels Airport, Atlas Copco, Flanders Investment and Trade, VDAB, Belga, Macadam, House of HR and many more. Visit our website https://radix.ai/ for client testimonials and case studies.\n\nWho we look for\n\nFor this role, we are looking for a passionate engineer who is deeply interested in how to efficiently develop, deploy and maintain Artificial Intelligence applications. You’re driven to get things done and deliver real, impactful solutions in close collaboration with our customers. You’re motivated by working in a vibrant team on diverse projects.\n\n\nYou have a master’s or Ph.D. in Computer Science, Mathematics or a similar field.\nYou have excellent general Software Engineering skills, and a deep knowledge of how those work in Python: maintainable code, testing, linting, type checking, … are no strange concepts to you.\nYou are proficient in “classic” DevOps: strong experience with setting up CI/CD systems with declarative pipelines (GitHub Actions, GitLab CI/CD, “modern” Jenkins, …), monitoring, dev-qa-prod environments, …\nYou know your way around tooling for version control and application/library packaging (Git, Poetry, Conda, pip, Docker, …). Experience with advanced version control tools for ML datasets and models (DVC, Azure ML dataset versioning, …) is a strong plus.\nYou have great familiarity with the most common ways of storing data: SQL & other databases, blob storage, … especially in the cloud. You have a keen understanding of differences between different storage methods and know when to use which ones.\nYou fluently handle deployments with Docker and Kubernetes on Cloud Infrastructure. Experience with modern GitOps tools (e.g. ArgoCD) is a strong plus.\nYou have a good knowledge of how Machine Learning models work.\nYou have excellent communication skills in English.\n\n\n\nWhy join us?\n\nYou’re not just joining a team, you’re stepping into the cockpit of AI innovation, collaborating with the crème de la crème and the brightest minds in the field. We're not just talking about the future of AI - we're actively shaping it. 🌟\n\n\nFlexibility: 🌈 work from home, or in our cool Brussels office right next to the central station\nHealth: Enjoy comprehensive hospitalization and dental insurance through DKV for you and your loved ones, plus group insurance. Like we said, our people come first. 💝\nPerks: meal and eco vouchers, full transportation cost coverage, monthly fixed cost, internet allowances, … we've got all the extras covered. 🦄\nOpportunities for personal initiative and professional growth. ⚡️\nEquipped with a MacBook Pro, phone subscription, and essential gadgets to keep your skills sharp. 🛠\nAdditional Radix holidays, so you can enjoy life outside of work too.",
    "companyName": "Radix ",
    "jobLocation": " Brussels, Brussels Region, Belgium",
    "jobPostDate": "7 months ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://pl.linkedin.com/jobs/view/mlops-engineer-at-emagine-3968174966?position=27&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=P8mhWx1urpxzRIUEf2yOjg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "PROJECT INFORMATION:\n\nIndustry: FinTech\n\nRemote work: 100%\n\nBusiness trips: once/month for 2-3 days to the office in Madrid, Spain. Expenses of the business trips are on the client.\n\nOn-boarding: Online or on-site from Madrid if the consultant is open to it.\n\nProject language: English\n\nProject length: 12-18 months (long-term project, at least untill 2027).\n\nStart: ASAP / September 2024\n\nAssignment type: B2B\n\nRemuneration: up to 160 PLN/h net + VAT (depending on the candidate’s experience)\n\nEquipment: Provided by the client.\n\nWe’re looking for a MLOps Engineer to join a team managing the core infrastructure of the company. The team consists of 6 people working with simillar tasks as needed on this position. We’re looking for an additional member not only for one project, but to be a help in development, maintainance and enhancing core functionalities for the whole organization.\n\nRESPONSIBILITIES:\n\n\nParticipating in the development and maintenance of the core infrastructure.\nBeing exposed to and participating in the end-to-end lifecycle of the projects.\nExtracting, integrating and deployment od API's.\nBeing involved in Cloud projects.\n\n\nREQUIREMENTS:\n\n\n3-4 years of experience on a simillar position.\nExperience with development and maintenance of infrastructure.\nExperience in working with API.\nTeamwork orientation.\nCan-do attitude and highly developed problem solving skills.\nStrong analytical and synthetical thinking skills.\nProficiency in English.\nTECH. STACK:\nMandatory skills: Python, Docker, Kubernetes, Jenkins, Git, Linux, MLflow, SQL\n\nNICE TO HAVE:\n\n\nExperience with Azure or any type of cloud.\nSkills in: PySpark/Spark, Terraform, Airflow, Graylog\nExperience in the FinTech industry.\n\n\nRECRUITMENT PROCESS:\n\n\nA short call with our recruiter.\nTechnical interview.\nTest assignment.\nFinal interview with the hiring manager.\n\n\nWe offer:\n\n\nLong-term cooperation.\nTransparently built relations based on trust and fair play.\nCo-financed benefits: Medicover card, Multisport card.",
    "companyName": "emagine ",
    "jobLocation": " Warsaw, Mazowieckie, Poland",
    "jobPostDate": "10 hours ago "
  },
  {
    "jobTitle": "MLOps Engineer (m/f/d)",
    "applicationLink": "https://hr.linkedin.com/jobs/view/mlops-engineer-m-f-d-at-walaris-3904703307?position=28&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=WLuaMBHF5QtslCRfldYrfQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Founded at Stanford University, Walaris develops autonomous AI-based solutions focused on enhancing situational awareness. Our AirScout software platform uses artificial intelligence, sensor fusion, and edge computing to detect threats in the air, on sea or on the ground. Our cutting-edge technology is utilized by commercial, government, and military users to increase situational awareness in and around sensitive locations.\n\nWe are seeking a talented MLOps Engineer to join our dynamic team and play a key role in designing and implementing robust MLOps pipelines, and optimizing ML models for real-world impact.\n\nFor our office in Zagreb, we are looking for an MLOps Engineer (m/f/d) starting as soon as possible{{:}}\n\nKey Responsibilities{{:}}\n\n\nBuilding data ingestion and MLOps pipelines{{:}} Utilize tools like Kubeflow, MLFlow, DataRobot, Airflow, Docker, and Kubernetes to streamline model development and deployment\nOrchestrate CI/CD pipelines{{:}} Collaborate with DevOps teams to automate the continuousintegration and delivery process using GitLab CI or similar tools\nMachine learning model optimization{{:}} Review, refactor, and optimize machine learning models forimproved performance, scalability, and eﬃciency\nContainerization and deployment{{:}} Containerize machine learning models and orchestrate theirdeployment, versioning, and monitoring\nModel testing and validation{{:}} Develop and automate tests to ensure the quality and reliability ofmachine learning models\nCollaboration and documentation{{:}} Work closely with cross-functional teams, including datascientists, data engineers, and architects. Document processes and best practices\n\n\n\nRequirements\n\n\n\nRequired Qualiﬁcations{{:}}\n\nBachelor's degree in computer science, software engineering, or a similar discipline\nProﬁciency with MLOps frameworks such as Kubeﬂow, MLFlow, DataRobot, and Airﬂow\nFamiliarity with Docker and Kubernetes, and experience with container orchestration\nStrong programming skills in Python and Bash. A solid understanding of Linux environments\nKnowledge of popular machine learning frameworks such as PyTorch, TensorFlow, Keras, andscikit-learn\nExperience with software development and test automation\nFluent in English with excellent communication skills\n\n\nDesired Qualifications{{:}}\n\n\nMaster's degree in in computer science, software engineering, or a similar discipline\nExperience in computer vision field and large-scale visual data management\nExperience in using AWS, Microsoft Azure, or Google Cloud Platform services is a plus\nExperience with CI/CD tools such as Jenkins is appreciated\n\n\n\nBenefits\n\n\n\nJoin our mission and our dynamic team! Help save lives and protect local and national security using bleeding edge technologies. This opportunity provides the chance to pioneer new fields and shoulder significant responsibility developing and deploying industry-defining solutions. At Walaris, you'll have creative freedom, receive competitive compensation, and work in a fast-paced environment.\n\nIf you're interested in learning more, please submit an application (cover letter, resume, and transcript) via our online application form.\n",
    "companyName": "Walaris ",
    "jobLocation": " Zagreb, Zagreb, Croatia",
    "jobPostDate": "3 months ago "
  },
  {
    "jobTitle": "MLOps / Machine Learning Engineer",
    "applicationLink": "https://es.linkedin.com/jobs/view/mlops-machine-learning-engineer-at-ntt-data-europe-latam-3918190753?position=29&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=eMfaym4wj8Oy3Pk3I68qKA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "NTT DATA is the 6th biggest IT Service Company in the world with more than 100.000 professionals and a turnover of more than 15 billion euros.\n\n\n\n\nWe at NTT DATA Spain make the difference by being close to our clients, exceeding expectations, managing proactively our projects and customers and focusing on quality and selecting employees with the right mindset to make our company grow. The Group has the ambitious goal to position within the TOP 3 worldwide. We have been awarded Best Place to work in Spain for 4 consecutive years.\n\n\n\n\nMLOps practices are both a strategic bet and a fast-growing initiative and thereby we are currently looking for a Data & Intelligence CoE LEADER. The position can be based in Spain Barcelona, even if the geographical scope is Europe. The desirable characteristics are:\n\n\n\n\nWhat are we looking for?\n\n\n\n\nWe are seeking a ML Engineer to our team to take on the technical design and implementation in projects within the scope of our Data & Intelligence CoE, working in initiatives for top-tier organizations.\n\n\n\n\nWe are looking for a professional who brings his knowledge and experience in artificial intelligence focused on:\n\n\n\n\nDefining and implementing technical solutions related to AI Platform framework/methodology.\nBuilding AI Platforms aligned with the logical version defined in high-level architecture designs. Being a cloud-native, hybrid or on-premises environment.\nBuilding CI/CD pipelines to orchestrate the MLOps life cycle aligned with client objectives and architecture requisites.\nContribute to the standardization of methodologies for development, training, deploying, inference and monitor of AI use cases.\nFacing challenges related to MLOps practices, provide resources and tools for Data Scientist, give them flexibility for model development and robust methodology to allow its productivization, train models in an unattended way, monitorize the model performance and generate retrain alarms.\n\n\n\n\nWhat will you be accountable for?\n\n\n\n\nYour responsibilities around our artificial intelligence services will be focused on the following fields of action:\n\n\n\n\nProject execution: ensuring the achievement of technical milestones in terms of effectiveness, efficiency and customer satisfaction. Identifying resources needed to do so while ensuring proper management of time, risk and quality.\nDevelopment of IaC scripts and pipelines to automate management and deployment of AI Platforms.\nDevelopment of CI/CD pipelines leveraging model development industrialization.\nDevelopment of custom software integrations to integrate external systems with the AI Platform.\nTechnical decision making.\n\n\n\n\n\n\n\nWhy would we want to meet you?\n\n\n\n\nWe want to meet you if:\n\n\n\n\nYou have 3 or more years of experience with AI-related projects.\nYou have experience working with IaC (CDK, Terraform, Ansible, etc.)\nYou have experience working with CI/CD tools (Jenkins, GitHub Actions, etc.)\nYou have strong coding skills in any of the most well-known Object-Oriented languages: Python, Java, C#, etc.\nYou have worked with artificial intelligence in a startup, large company or academic environment helping Data Scientist to deploy their work in production.\nYou are oriented to achieving high quality results and continuously improving.\nYou are committed to transmitting knowledge to the entire team.\n\n\n\n\nWe will positively value:\n\n\n\n\nExperience with MLOps tools and frameworks, either from the Open-Source community or from a specific cloud provider.\nBuilding CI/CD pipelines in the context of artificial intelligence.\nSoftware design patterns knowledge.\nData Engineering skills and knowledge.\nExperience with model and data monitoring.\nIAM knowledge (users, groups, roles, permissions, etc.)\n\n\n\n\nWhat do we offer?\n\n\n\n\nWe propose:\n\n\n\n\nTo work on projects for leading companies in Spanish and European market.\nTo be involved in high priority projects with visibility to senior leadership\nTo apply the latest technical innovations in artificial intelligence platforms in AWS.\nTo attend and give conferences.\nTo join the team of a consolidated multinational such as NTT Data, which shares with you its professional interests and enjoys applying artificial intelligence in large companies and public agencies.\nA competitive salary according to provided experience.\nA career path that ensures your professional development and continuous improvement (language courses, management and professional skill training, technical training and certifications).\n\n\n\n\nIf you are interested or would like to have more information, please apply via this advertisement.",
    "companyName": "NTT DATA Europe & Latam ",
    "jobLocation": " Barcelona, Catalonia, Spain",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOps, AI/ML",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-ai-ml-at-tata-consultancy-services-3952533721?position=30&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=uKBg6G7DuQLVO18kwtecMg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Role**: MLOps\n\nRequired Technical Skill Set** Machine learning (ML), Data Science, Statistical modeling. Python Programming, Linux/Unix shell scripting.\n\nDesired Experience Range**: 4 – 7 years\n\nLocation of Requirement : Mumbai\n\nDesired Competencies (Technical/Behavioral Competency)\n\nMust-Have**\n\nMachine learning (ML), Data Science,Statistical modeling.\nPython Programming, Linux/Unix shell scripting.\nDevelop and maintain a platform that automates creating, training, deploying and updating machine learning models.\nBuild, maintain, and optimize machine learning solutions\nexperience building large-scale data pipelines\n\nGood-to-Have\n\nDevops Knowledge\n\nResponsibility of / Expectations from the Role\n\n1. Understanding the requirements.\n\n2. designs, builds, and runs machine learning systems at scale.\n\n3. maintaining the infrastructure that supports the models and algorithms that power the products\n\n4. improving your model's accuracy by tweaking its parameters or updating the data it uses for training\n\n5. Develop and maintain a platform that automates creating, training, deploying and updating machine learning models.\n\n6. Customer Product Documentation\n\n7. Participation in trouble report reviews and analysis\n\n8. System Integration Testing",
    "companyName": "Tata Consultancy Services ",
    "jobLocation": " Mumbai, Maharashtra, India",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "Data Scientist / MLops",
    "applicationLink": "https://es.linkedin.com/jobs/view/data-scientist-mlops-at-ad4-oct%C3%B3gono-3963078366?position=31&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=byN7gIdi1jgSVMoTkD%2BCbA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "En AD4 Octógono estamos contratando un Data Engineer con conocimientos/experiencia en MLops con, al menos, dos años de experiencia en posición similar.\n\nPodrás trabajar en un ambiente dinámico y colaborativo.\n\nOportunidad de aprender y crecer profesionalmente.\n\nSalario competitivo acorde a tu experiencia y habilidades.\n\nModalidad hibrida en Madrid y Andalucia (Jaen, Cordoba, Granada, Sevilla) y remota en otras locaclizaciones.\n\nRequisitos:\n\n\nExperiencia mínima de 2 años como Data Scientist\nAnalizar grandes volúmenes de datos.\nAplica la tecnología disponible para comprenderlos.\nExtraer la información valiosa.\nConstruir modelos predictivos\nEstudiar comportamiento de los datos, su relación con la realidad y extraer conclusiones a partir de los datos.\nOptimización y escalabilidad de los sistemas de datos.\nSkills:\nR o Python\nETL\nBBDD: SQL y NoSQL\nML (Tensorflow, Keras, Scikit-learn,...) y MLops (CI/CD, pipelines, MLFlow,...)\nVisualización de datos\nValorables:\nExperiencia con Arquitecturas de datos (Data Lake, Data Factory, ...)\nOrquestación de procesos\nCloud Computing (AWS, Azure, GCP)",
    "companyName": "AD4 Octógono ",
    "jobLocation": " Madrid, Community of Madrid, Spain",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOPS ENGINEER",
    "applicationLink": "https://pl.linkedin.com/jobs/view/mlops-engineer-at-svitla-systems-inc-3962219082?position=32&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=IuBRLFPrBE09iANfukD%2BZA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "1 position\n\nMLOPS ENGINEER\n\nlocation\n\nAny city, Poland\n\nSvitla Systems Inc. is looking for an MLOps Engineer for a full-time position (40 hours per week) in Poland. Our client is a broker platform that offers brokers real-time risk capacity anytime, anywhere. It is a genuine step-change from the current manual and time-consuming process available in the market, providing unprecedented service to brokers and clients. It is a first-of-its-kind digital model that claims to deliver a unique advantage to its business partners. It is the first fully digital and automatically driven Lloyd’s of London syndicate. They are transforming the following market within Lloyd's by revolutionizing the broker and client experience, taking an algorithmic approach to underwriting, and creating a learner operation model to benefit all market participants in the long term. They developed and created a platform in 2021, together with partners at Google and UCL, that helps insurance brokers place risks quickly and frictionlessly. They’re continuing to lead the charge on the digitization of this market, and we need more excellent minds to work with us to realize this goal and create more opportunities.\n\nRequirements\n\n\n3+ years of experience in MLOps.\nKnowledge of Python (including expertise with FastAPI, Pandas, etc.).\nUnderstanding of cloud platforms (e.g., GCP).\nStrong knowledge of CI/CD pipelines (e.g., GitHub Actions).\nFamiliarity with containerization and orchestration (Docker, Kubernetes).\n\n\nNice To Have\n\n\nUnderstanding of writing ETLs.\nFamiliarity with Feast.\nFamiliarity with Vertex AI.\nExperience with event-driven architectures.\nExperience with MLflow.\nExperience with Seldon.\n\n\nResponsibilities\n\n\nDevelop and evolve the MLops platform to expand its support for non-ML models (e.g., rule-based and actuarial models).\nWork with colleagues to design, deliver, and evolve the end-to-end MLOps system.\nEnable colleagues across the project to deliver models more quickly and safely into production.\nAdvocate and uphold model management best practices.\nDrive improvements in the way to operate as a digital underwriting capability.\n\n\nWe Offer\n\n\nUS and EU projects based on advanced technologies.\nCompetitive compensation based on skills and experience.\nAnnual performance appraisals.\nFlexibility in workspace, either remote or in our welcoming office.\nComprehensive medical insurance after one month.\nMultiSport card with access to 2500 sports facilities all over Poland\nBonuses for recommendations of new employees.\nBonuses for article writing, public talks, other activities.\n15 vacation days, 10 national holidays, sick leaves, family days off.\nEducational activities reimbursement on the monthly basis.\nFree webinars, meetups and conferences organized by Svitla.\nGifts for anniversaries, New Year, children and more.\nFun corporate celebrations and activities.\nAwesome team, friendly and supportive community!\n\n\nAbout Svitla\n\nSvitla Systems is a global trusted IT solutions company headquartered in California, with business and development offices throughout the US, Latin America, Europe, and Asia. Svitla is an outspoken advocate of workplace flexibility, best known for its well-established remote culture, individual approach to our teammate’s professional and personal growth, and family-like environment.\n\nSince 2003, Svitla has served a wide range of clients, from innovative start-ups in California to mega-large corporations such as Ingenico, Amplience, InvoiceASAP and Global Citizen. At Svitla, developers work with clients’ teams directly, building lasting and successful partnerships, as a result of seamless integration with on-site processes.\n\nSvitla Systems’ global mission is to build a business that contributes to the well-being of our partners, personnel and their families, improves our communities, and makes a lasting difference in the world. Join us!",
    "companyName": "Svitla Systems, Inc. ",
    "jobLocation": " Cracow Metropolitan Area",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-at-techshack-3966088331?position=33&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=kdyP%2BCGZiWuXUcSzOne4WQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "MLOps Engineer\n\n\n\n\nWe're working with a leading AI/Blockchain business who are looking for an MLOps Engineer.\n\n\n\n\nAs an MLOps Engineer within the business, you will work closely with the Data Engineering and DevOps functions.\n\n\n\n\nKey skills for the MLOps Engineer:\n\n3 years of professional experience as a Machine Learning Engineer, Data Engineer, DevOps Engineer, or MLOps Engineer, focusing on deploying machine learning pipelines at scale.\nStrong programming skills in Python, with expertise in machine learning frameworks.\nProficiency in containerisation technologies.\nExperience with data pipelines, data warehousing, and ETL processes.\n\n\n\n\nLocation: once a quarter in London\n\nSalary: £80K - £100K\n\n\n\n\nMLOps Engineer",
    "companyName": "TechShack ",
    "jobLocation": " United Kingdom",
    "jobPostDate": "2 days ago "
  },
  {
    "jobTitle": "Junior MLOps Engineer",
    "applicationLink": "https://bg.linkedin.com/jobs/view/junior-mlops-engineer-at-sap-3956348761?position=34&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=blXZ6JCxnLVkywyJobUUwA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Bring out your best\n\nSAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best.\n\nThe development center of SAP in Bulgaria plays a key role in the defining and developing of the SAP Business Technology Platform. With its more than 1400 professionals, SAP Labs Bulgaria also has strong contributions toward life-cycle management, user interface & user experience across the broader portfolio of SAP products and has recently welcomed new teams focusing on business applications. For its 24-year history, the company has established itself as a preferred employer in the IT sector in Bulgaria.\n\nAbout Us\n\nSAP Intelligent Enterprise Solutions (IES) organization, also known as SAP IT, has the purpose to “Deliver and Run the Intelligent Enterprise”. IES is SAP’s technology backbone and most compelling reference customer, and as such, we influence SAP product development and strategy, with our customer experience at heart. To support the updated SAP AI Strategy and the company vision on Generative AI, we need to strengthen our team to accelerate delivery of Data & AI Cloud Solutions.\n\nTHE ROLE\n\nWe’re looking for a MLOps Engineer with background in Machine Learning and DevOps and with an entrepreneurial spirit to join our Data Science, AI and Big Data team and work on innovation projects. As a MLOps Engineer, you will join the AI Platform Enablement agile team and work closely with Data Scientists, Engineers and Product Owner in an agile, cross-functional setup to help deliver AI infrastructure as well as ML models for our customer’s use cases to provide business benefits and tackle customer’s pain-points through AI technologies.\n\nWhat You’ll Do\n\n\nWork on development and conceptual tasks along the entire AI product lifecycle as well as on technology-related enablement of AI Platform users within an agile team.\nContribute to building of reusable software components required for fast delivery of productive ML models, increased process automation and accelerated adoption of MLOps best practices.\nContinuous learning and familiarization with state-of-the-art algorithms and technologies in agile software engineering, MLOps and AI.\nOpenness to conduct data science tasks in our AI projects including knowledge in Python libraries and Machine Learning frameworks\n\n\nWhat You’ll Bring\n\n\nBachelor’s or master’s degree in computer science, data science, engineering or related technical fields\nUnderstanding of AI/ML concepts with focus on MLOps\nUnderstanding of Machine Learning frameworks such as Numpy, Pandas, Keras, scikit-learn, TensorFlow, PyTorch\nExperience in DevOps practices and tools such as Jenkins, GitHub, Terraform\nExperience with large-scale data processing frameworks such as Spark.\nKnowledge in Azure cloud services, Azure DevOps and related tools for successful end-to-end deployment and management of machine learning solutions will be considered a plus\n\n\nBring out your best\n\nSAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best.\n\nWe win with inclusion\n\nSAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.\n\nSAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com\n\nFor SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.\n\nEOE AA M/F/Vet/Disability\n\nQualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.\n\nSuccessful candidates might be required to undergo a background verification with an external vendor.\n\nRequisition ID: 394292 | Work Area: Information Technology | Expected Travel: 0 - 10% | Career Status: Graduate | Employment Type: Regular Full Time | Additional Locations: .\n\n",
    "companyName": "SAP ",
    "jobLocation": " Sofia, Sofia City, Bulgaria",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-at-xcede-3963967653?position=35&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=d3c64dcIL6uG%2FXTFMxOZ%2FA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "MLOps Engineer\n\n(London – visit the office x3 days a week)\n\n\n\n\nXcede are delighted to be working with a very exciting scale-up Tech Product organisation. With a fledgling Data Science team already in place who focus on recommendation systems and customer personalisation, the company now want to hire an MLOps Engineer / ML Engineer to focus on machine learning infrastructure and deployment tech. As the first person focusing solely on this skillset in the near future, we’ll need a capable and experienced engineer who is happy making independent technical decisions.\n\n\n\n\nResponsibilities\n\nDeploy, optimise and maintain the machine learning models at the core of the company’s product offering.\nFocus on creating state of the art recommendation system and graph network technology that is scalable and stable.\nBuild APIs for the product.\nDrive smart and necessary DevOps decision within the ML function – MLOps.\n\n\n\n\nRequirements\n\nStrong academic background in a relevant field (Statistics, Computer Science, etc.)\nSignificant commercial experience deploying and maintaining (MLOps) Machine Learning algorithms and infrastructure. This would ideally be in a digital B2C product or platform.\nSome experience of deploying recommendation engines / recommender systems / RecSys\nStrong cloud experience – ideally AWS / Amazon Web Services.\nUsage of LLMs in a commercial environment is a bonus.\nDocker & Kubernetes experience\nBonus experience – pathfinder algorithms, graph network experience\n\n\n\n\nIf this role interests you and you would like to find out more, please apply here or contact us via niall.wharton@Xcede.com (feel free to include a CV for review).",
    "companyName": "Xcede ",
    "jobLocation": " London Area, United Kingdom",
    "jobPostDate": "2 days ago "
  },
  {
    "jobTitle": "MLOPs",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-at-tech-mahindra-3965463171?position=36&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=FlHvRXDIKM3p2pCjPSpoDA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Job Summary\n\nTo ensure successful initiation, planning, execution, control and completion of the project by guiding team members on technical aspects, conducting reviews of technical documents and artefacts. Lead project development, production support and maintenance activities. Fill and ensure timesheets are completed, as is the invoicing process, on or before the deadline. Lead the customer interface for the project on an everyday basis, proactively addressing any issues before they are escalated. Create functional and technical specification documents. Track open tickets/ incidents in queue and allocate tickets to resources and ensure that the tickets are closed within the deadlines. Ensure analysts adhere to SLA¿s/KPI¿s/OLA¿s. Ensure that all in the delivery team, including self, are constantly thinking of ways to do things faster, better or in a more economic manner. Lead and ensure project is in compliance with Software Quality Processes and within timelines. Review functional and technical specification documents. Serve as the single point of contact for the team to the project stakeholders. Promote team work, motivate, mentor and develop subordinates. Provide application production support as per process/RACI (Responsible, Accountable, Consulted and Informed) Matrix.\n\n",
    "companyName": "Tech Mahindra ",
    "jobLocation": " Bengaluru, Karnataka, India",
    "jobPostDate": "8 hours ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://www.linkedin.com/jobs/view/mlops-engineer-at-clarifai-3952878718?position=37&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=i0alWYaox3m6WcBvj9iePA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "About the Company\n\n\n\n\nClarifai is a leading, full-lifecycle deep learning AI platform for computer vision, natural language processing, and audio recognition. We help organizations transform unstructured images, video, text, and audio data into structured data at a significantly faster and more accurate rate than humans would be able to do on their own. Founded in 2013 by Matt Zeiler, Ph.D. Clarifai has been a market leader in AI since winning the top five places in image classification at the 2013 ImageNet Challenge. Clarifai continues to grow with employees remotely based throughout the United States, Canada, Estonia, Argentina & India.\n\n\n\n\nWe have raised $100M in funding to date, with $60M coming from our most recent Series C, and are backed by industry leaders like Menlo Ventures, Union Square Ventures, Lux Capital, New Enterprise Associates, LDV Capital, Corazon Capital, Google Ventures, NVIDIA, Qualcomm and Osage.\n\n\n\n\nClarifai is proud to be an equal opportunity workplace dedicated to pursuing, hiring, and retaining a diverse workforce.\n\n\n\n\nThe Opportunity\n\n\n\n\nNote: We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas for this particular opportunity, as we are looking for someone who is eligible for a Secret or Top Secret Clearance.\n\n\n\n\nJoin our high-velocity, talented AI research and software engineering teams to build innovative Applied Computer Vision and Enterprise AI solutions addressing critical public sector problems. You will maintain data ingestion and model development pipelines with a strong focus on detail and testing, deploy cutting-edge AI algorithms into production, and build and maintain efficient pipeline tooling. This role allows you to make a significant impact on both the company and the broader AI field by solving challenging customer problems and integrating real-world ML Ops pipelines into the Clarifai platform.\n\n\n\n\nKey Responsibilities:\n\n\n\n\nCollaborate with scientists and engineers to enhance object detection, segmentation, tracking, and visual search capabilities and develop new products.\nDeploy production-ready models to customers and iteratively improve them based on feedback.\nMaintain our research ML infrastructure.\nTransition research projects from proof of concept to production.\nIntegrate your work directly into Clarifai’s AI orchestration platform\n\n\n\n\nImpact\n\n\n\n\nYou will drive customer acquisition and revenue growth, working closely with various teams across the company, including research, backend, infrastructure, product, frontend, and design. This role offers a unique opportunity to make a substantial impact on the company and the AI industry.\n\n\n\n\nRequirements\n\n\n\n\n3+ years of experience with Python, focusing on Machine Learning or Computer Vision (PyTorch/TensorFlow).\nStrong MLOps philosophy and experience with associated tooling (Git, CI/CD, Docker, Kubernetes, Kubeflow, Hydra).\nExperience building and maintaining CI/CD pipelines with an emphasis on DevOps best practices.\n3+ experience with large scale software development: testing, automation, system-design, performance optimization, concurrent development\n3+ years of cloud exposure: AWS, Google Cloud, Azure (at least one of them)\nComfortable working in a shell environment.\nExperience working with complex existing codebases.\nEligible to obtain a U.S. Secret Security Clearance (U.S. Citizenship)\n\n\n\n\nGreat to Have\n\n\n\n\nExperience in object detection and tracking.\nExperience with model export (Torchscript, TensorRT).\nExperience with Golang, relational databases.\n\n\n\n\nThe salary hiring range for this position is $125,000 - $175,000 and flexible depending on relevant experience.",
    "companyName": "Clarifai ",
    "jobLocation": " Washington DC-Baltimore Area",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://fr.linkedin.com/jobs/view/mlops-engineer-at-understanding-recruitment-3965932740?position=38&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=AI%2F7QsHrG%2FFaw8u8tq5QMQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "MLOps Engineer\n\n\n\n\nWe are seeking an MLOps Engineer to join a well-funded scale up using ML to significantly reduce global carbon emissions.\n\n\n\n\nThe teams AI platform aims to accelerate research and discovery in materials science, allowing manufacturers (in areas like fertilizers, cement & ammonia manufacturing, producing around 10% of global carbon emissions) to reduce both production costs & their emissions footprint.\n\nThey aim to use ML to make a real impact.\n\n\n\n\nThe platform and Founders have attracted a lot of interest, and have recently closed a significant funding round in a very challenging funding environment.\n\n\n\n\nYour mission will be to design and develop a cloud infrastructure backbone that can meet the computational demands of high performance computing in AI research. Working closely with the research and ML engineering team to deploy models into cloud environments, monitoring and analysing performance and ensuring robust scalability and security processes.\n\n\n\n\nWe are seeking an MLOps Engineer with:\n\n\n\n\nExperience building and managing ML infrastructure, supporting high performance computing\nDemonstrable experience working with major cloud providers building cloud infrastructure, either AWS or GCP\nStrong development knowledge (Python preferred) with the ability to script for automation\nA desire to work in an early stage scale up team, using ML to make a real impact on a challenging global issue\n\n\n\n\nSalary: €65,000 to €100,000 plus stock (BSPCE) and health\n\nLocation: Central Paris operating on a hybrid basis, ideally three or four days per week in office.",
    "companyName": "Understanding Recruitment ",
    "jobLocation": " Paris, Île-de-France, France",
    "jobPostDate": "2 days ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-at-deeprec-ai-3964529911?position=39&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=3AYw4nhEQzMmtc9sR9O%2F6Q%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Join a leader in generative AI technologies, who have recently secured Series A funding to advance our work in digital avatars and human clones.\n\n\n\n\nRole: MLOps Engineer\n\nLocation: London\n\nSalary: Up to £100,000\n\n\n\n\nResponsibilities:\n\nDevelop ML Pipelines: Build and maintain scalable data processing systems. Ensure data quality and integrity.\nAutomate ML Processes: Integrate machine learning solutions into existing systems and automate workflows.\nDeploy and Scale Models: Manage the deployment of ML models to production, ensuring scalability.\nMonitor and Optimize: Oversee model performance and conduct periodic tuning.\nCollaborate on Innovations: Work with cross-functional teams to improve model performance and implementation practices.\nEnsure Security: Adhere to security and compliance standards in ML deployments.\n\n\n\n\nRequirements:\n\nEducation: Bachelor’s or Master’s in Computer Science, Data Science, or related field.\nExperience: 2-3 years in ML, data engineering, or MLOps.\nAbilities: Strong analytical, problem-solving, and communication skills.\n\nSkills:\n\nProficient in Python, ML frameworks like TensorFlow or PyTorch.\nExperienced with CI/CD, Docker, Kubernetes, and data pipeline tools like Airflow.",
    "companyName": "DeepRec.ai ",
    "jobLocation": " London Area, United Kingdom",
    "jobPostDate": "4 days ago "
  },
  {
    "jobTitle": "MLOps Engineer - Grand Rapids, MI",
    "applicationLink": "https://www.linkedin.com/jobs/view/mlops-engineer-grand-rapids-mi-at-software-technology-inc-3941634235?position=40&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=E0oFx0zGJll18AbXyJtriA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Qualifications\n\n\nBachelor's degree in Computer Science, Engineering, or related field (Master's preferred).\nProven experience as an MLOps Engineer or similar role, with a strong track record of deploying and managing machine learning models in production.\nProficiency in programming languages such as Python, and experience with popular ML frameworks like TensorFlow or PyTorch.\nFamiliarity with containerization technologies like Docker and orchestration tools like Kubernetes.\nExperience with cloud platforms such as AWS, Azure, or Google Cloud.\nSolid understanding of CI/CD principles and tools like Jenkins, CircleCI, or GitLab CI/CD.\nStrong knowledge of version control systems, preferably Git.\nExperience with monitoring tools and frameworks like Prometheus, Grafana, or ELK Stack.\nAbility to collaborate effectively with cross-functional teams and communicate technical concepts clearly.\nExcellent problem-solving skills and a proactive approach to troubleshooting and resolving issues.\nStrong attention to detail, organizational skills, and ability to manage multiple tasks and projects simultaneously.\nExperience with infrastructure as code (IaC) tools like Terraform or Ansible is a plus.",
    "companyName": "Software Technology Inc. ",
    "jobLocation": " Grand Rapids, MI",
    "jobPostDate": "1 month ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://nl.linkedin.com/jobs/view/mlops-engineer-at-foxtek-3959650632?position=41&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=839rw6K2HZ0p90s%2BL7i9fQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Looking for a role that blends Software Engineering with Machine Learning?\n\n\n\n\nWant to work in a super modern stack on a real-time, global product?\n\n\n\n\nOur client's looking for a Python Engineer to join the team with Machine learning experience.\n\n\n\n\nYou'll focus on building API's and deploying the models created by scientists into production. The role is therefore a mix of a Python Engineer & Machine Learning Engineer, otherwise known as MLOps.\n\n\n\n\nThe product is extremely innovative, complex and used all over the world!\n\n\n\n\nEssential Experience\n\n\n\n\nStrong Python experience writing API's\nMachine learning experience - specifically deploying models created by Data Scientists into production (MLOps)\nDocker\nRelational / Non-Relational Databases\nPublic cloud\nAt least 2 years experience\n\n\n\n\nBeneficial Experience\n\n\n\n\nKubernetes\nBig Data experience\nMongoDB\nEvent Driven Architecture\nReal-time experience\nAirflow\n\n\n\n\nStart - Next 2-3 months\n\n\n\n\nSalary - 70-85K including the 8% holiday allowance\n\n\n\n\nHybrid - 2 days a week working at the office in Amsterdam (Tuesday & Thursday)\n\n\n\n\nThis company can provide visa sponsorship and 30%\n\n\n\n\nNOTE - You must already be in the Netherlands\n\n\n\n\nInterested to know more information - apply now!",
    "companyName": "Foxtek ",
    "jobLocation": " Amsterdam, North Holland, Netherlands",
    "jobPostDate": "2 days ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-at-pynea-3821875664?position=42&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=WzB3SX%2B5NcMsCryOwM%2BFYg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "As the first Pipeline-Centric MLOps Engineer at Pynea, you will play a vital role in shaping and building our modern, collaborative, social network. You will be responsible for developing, implementing and optimising models that drive core features and services within the app. You will work with large and complex data sets to derive insights that inform product development and our business strategies. You will work closely with product, engineering, and commercial teams to integrate and maintain these models.\n\nThe Company\n\nOur company culture is collaborative, ambitious, and driven. We believe that the best products are built by teams that work together, challenge each other, and are committed to achieving a common goal. We encourage open communication, transparency, and feedback. We value diversity, inclusivity, and creativity, and believe that every team member has something valuable to contribute.\n\nWe are a young company with big ambitions, and we are looking for someone who shares our passion for building something new and exciting. We believe that our success will be driven by our ability to attract and retain the best talent, and we are committed to creating a work environment that is challenging, rewarding, and fulfilling.\n\nIf you are excited about the opportunity to help build a new social media platform from the ground up, and if you are passionate about technology, deep learning, AI, product development, and building great teams, then we would love to hear from you.\n\nYou Will:\n\n\nDevelop, implement, and optimise machine learning models to support core Pynea features and services.\nDevelop and deploy state-of-the-art recommendation algorithms using Python and relevant libraries (e.g., TensorFlow/PyTorch/Keras/ etc) in the Python ecosystem.\nDeploy models and make them accessible via. API to be consumed by the Pynea backend.\nHave strong experience in DevOps combined with AWS (or equivalent GCP) technologies such as Docker, Kubernetes, EC2, ECR, ECS, Glue, Lambda, S3, Cloud Formation, Cloudwatch etc.\nHave proven experience deploying models and ML pipelines at scale, including exprience using AWS SageMaker and/or Google Cloud AI.\nSupport and drive implementation of features around NLP and LLMs.\nTackle challenges related to user recommendation/matching, suspicious usage patterns, content discovery, tag mapping and data categorisation.\nAnalyse large and complex data sets to derive valuable insights that inform product development and business strategies.\nBenchmark algorithms and models for data-driven product iteration. Using standard metrics and live user data.\n\n\nYou Will Thrive if You Have:\n\n\nHave 3+ years industry experience as a Machine Learning Engineer, Data Engineer, DevOps or MLOps Engineer, specialising in deploying machine learning pipelines at scale.\nCare deeply about AI, Deep Learning and its ability to craft seamless product experiences with direct real world applications.\nExperience deploying pipelines for recommendation systems, including online deployment and real-time updates.\nExperience with large distributed systems, deep learning, neural networks and/or natural language processing.\nStrong problem-solving skills and ability to think algorithmically.\nExcellent communication skills and can effectively collaborate with cross-functional teams.\n\n\nThis Role Is Not For You If:\n\n\nYou live in the realm of theory but have not demonstrated being able to operationalise it.\nYou require significant direction and hand-holding.\nYou're unsure of your ability to deliver category defining work.\n\n\nBonus Experience:\n\n\nYou have worked in Big Tech, SaaS, Eccom, or an Ads Network Previously\nGraph data structures, path-finding and link prediction algorithms\nYou have a startup mentality\nExperience with AWS.\nFamiliarity with the social networking or B2C space.\nDegree in Computer Science, Data Science, Mathematics, or a related field.\n\n\nPynea is an equal opportunities employer and does not discriminate on the basis of race, religion, natural origin, gender, sexual orientation, disability, age or any other legally protected status. The users for Pynea are diverse, and we know we must build a diverse team in order to meet their needs effectively.",
    "companyName": "Pynea ",
    "jobLocation": " London, England, United Kingdom",
    "jobPostDate": "5 months ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-at-adlib-recruitment-b-corp%E2%84%A2-3841206005?position=43&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=d%2FKoBu8KAgr72km9eVJvjw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Competitive Salary Circa £90k With Comprehensive Benefits.\n\nFlexible working options and a culture of autonomy and innovation.\n\nBe at the forefront of ML, making a tangible impact.\n\nJoin an innovative tech-driven company that’s changing the financial services landscape through advanced machine learning and data-driven insights.\n\nAs an MLOps Engineer, you’ll play a pivotal role in shaping their future, leveraging your expertise to enhance their ML platform, streamline operations, and drive continuous improvement.\n\nWhat you’ll be doing:\n\nYou’ll collaborate with a dynamic team of ML Engineers and Data Scientists to design, build, and maintain scalable machine learning systems. Your work will directly contribute to their mission of delivering fair, transparent, and accessible solutions. Key responsibilities include:\n\n\nDeveloping and optimising ML infrastructure to support model training and deployment, ensuring high performance, reliability, and scalability.\nAutomating ML workflows to enable rapid experimentation and seamless production deployments.\nImplementing monitoring and logging for machine learning models to track performance and detect anomalies.\nEnhancing collaboration between ML Engineers and Data Scientists, fostering a culture of innovation and continuous learning.\n\n\nExperience you’ll need to apply:\n\n\nProven experience in MLOps or a similar role.\nProficiency in cloud technologies and infrastructure as code (e.g., AWS, GCP, Azure).\nSolid CI/CD practices and experience with related tools (e.g., Jenkins, GitLab).\nExperience with containerisation and orchestration technologies (e.g., Docker, Kubernetes).\nFamiliarity with data processing and storage frameworks (e.g., Kafka, Spark, Hadoop).\nA collaborative mindset and excellent communication skills, able to work effectively across teams.\n\n\nWhat you’ll get in return for your experience:\n\n\nA competitive salary of circa £90k, reflecting your skills and experience.\nFlexible & hybrid working arrangements (2 days per week in the office), supporting work-life balance.\nA generous benefits package, including a flexible benefits budget, private healthcare, mental wellbeing support, and a comprehensive tech scheme.\nAn inclusive and dynamic workplace culture, with regular team and company-wide socials.\n\n\nWhat next:\n\nIf you’re ready to take on this exciting role and make a significant impact at a forward-thinking company, we’d love to hear from you. Apply now with an up-to-date CV",
    "companyName": "ADLIB Recruitment | B Corp™ ",
    "jobLocation": " London, England, United Kingdom",
    "jobPostDate": "4 months ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-engineer-at-changeleaders-in-3882804789?position=44&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=VwlqqzD06tdx5zx4KHqVCw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Python, ML concepts and frameworks, Fast API, Graph QL, AWS, ML Flow, AirFlow, ML pipeline creation, drift monitoring\n\nStrong understating of Python, ML concepts and frameworks, Fast API, Graph QL\n\nExperience in developing scalable APIs.\n\nKnowledge of AWS, preferred services are storage, EC2, Kubernetes\n\nExposure of ML best practices, documentation and unit testing.\n\nML Flow, AirFlow, ML pipeline creation, drift monitoring and control\n\nExperience in developing and deploying machine learning models in a production environment using CI/CD.\n\nCommunicate with clients to understand requirements and ask right questions.\n\nKnowledge of Django and database design will be added advantage.\n\nStrong analytical and problem-solving skills.",
    "companyName": "Changeleaders.in ",
    "jobLocation": " Karnataka, India",
    "jobPostDate": "3 months ago "
  },
  {
    "jobTitle": "Ingénieur MLOps H/F 100% REMOTE",
    "applicationLink": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-mlops-h-f-100%25-remote-at-externatic-3909847740?position=45&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=7yObQRKVJiVp%2FkM8NZODRA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Présentation de la société\n\nCabinet de recrutement Tech, la mission d’Externatic est de faciliter la rencontre entre candidats et entreprises. Nous mettons notre réseau et notre connaissance du marché de la Tech (étude des salaires, tendances) à votre disposition pour vous épauler dans toutes les étapes de votre recherche.\n\nNotre moteur : vous accompagner sur du long terme pour trouver l’opportunité en CDI, qui correspond à votre projet professionnel, et surtout vous proposer un accès privilégié à des opportunités cachées au sein de pépites (startup / éditeur / DSI / PME).\n\nChez nous, le côté humain prime et nous sommes transparents sur nos actions : ici, chaque offre d’emploi correspond à un poste réel !\n\nMission\n\nJe suis Cyrille, Consultant recrutement chez Externatic, je vous propose aujourd’hui de découvrir l’offre ci-dessous et d’échanger ensemble : plutôt en visio ? Ou autour d’un verre ? Je serai ravi de vous accompagner et de vous présenter ce job plus en détail !\n\nJe recrute pour un de nos clients, scale up américaine évoluant dans le domaine de la santé proposant des solution Data, dopées à l'IA, un ML Ops (H/F)\n\nEn tant que MLOps vos missions principales :\n\n\nConcevoir, développer et maintenir des pipelines de déploiement ML robustes et évolutifs.\nAutomatiser les processus de formation, d'évaluation et de déploiement des modèles.\nCollaborer avec les équipes d'ingénierie et de science des données pour garantir des intégrations transparentes.\nAssurer la surveillance et l'optimisation des performances des modèles en production.\nMise en place de LLM et d'IA Génératives\nContribution à la création de ses models en utilisant les LLM du marché (Mistral, Hugging Face, Llama...)\n\n\nProfil\n\nDe formation supérieure, vous disposez d'une expérience en Machine Learning. Vous avez déployé des modeles en production à grande échelle.\n\nVous maitrisez MLflow, Python et avez eu idéalement un première approche des LLM (Mistral, Open AI, Llama\n\nVous parlez anglais couramment\n\nAvantages\n\n\n100% Remote\nEnvironnement international\nProjet qui a du sens\nChallenge technique",
    "companyName": "Externatic ",
    "jobLocation": " Paris, Île-de-France, France",
    "jobPostDate": "2 months ago "
  },
  {
    "jobTitle": "MLOps Engineer,",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-engineer-at-yo-hr-consultancy-3916821668?position=46&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=9LIZxQzJ0s%2FqdjnUkAp95A%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Senior Machine Learning Operations Engineer\n\nLocation: Permanent Remote\n\nJob Description\n\nAs a Senior Machine Learning Operations (MLOps) Engineer, you will be instrumental in deploying robust, scalable machine learning solutions. You will ensure these are tailored to meet the expansive needs of a client in healthcare services. This role demands a high level of proficiency in machine learning technologies and programming, coupled with rigorous vetting processes to maintain the highest standards of data integrity and security.\n\nKey Responsibilities\n\n\nRapidly develop and deploy production-ready ML models, with a focus on scalability and monitoring across a broad range of applications within healthcare.\nWrite efficient, maintainable, and scalable Python code tailored to our specific business needs.\nBuild high-performance, multi-tenant deployment architectures and sophisticated model monitoring systems.\nDirectly engage with internal stakeholders to incorporate feedback and refine our ML-driven products through quick iteration cycles\nUphold stringent security protocols and processes in the deployment and maintenance of machine learning models.\nDrive the continuous advancement of MLOps practices within the healthcare industry by developing innovative solutions and advocating for best practices.\n\n\nRequirements\n\n\nMinimum 3 years of experience with transformer-based models and NLP, preferably in a healthcare context.\nStrong track record of fine-tuning, running large-scale training jobs, and managing model servers like vLLM, TGI, or TorchServe.\nProficiency in data science tools such as Pandas, Notebooks, Numpy, Scipy.\nExperience with both relational and non-relational databases.\nExtensive experience with TensorFlow or PyTorch, and familiarity with HuggingFace.\nKnowledge of model analysis and experimentation frameworks such as MLFlow, W&B, and tfma is preferred.\nComfortable with a Linux environment and stringent data security practices.\nMust pass a rigorous vetting process, including extensive background checks to ensure the highest standards of data security and integrity.\n\n\nSkills: healthcare context,pandas,mlops,nlp,huggingface,machine learning,transformer-based models,pytorch,operations,model analysis,ml,healthcare,scalability,tensorflow,model monitoring,linux environment,python,experimentation frameworks,numpy,non-relational databases,relational databases,machine learning operations,data science tools,deployment architectures,data security practices",
    "companyName": "YO HR Consultancy ",
    "jobLocation": " India",
    "jobPostDate": "2 months ago "
  },
  {
    "jobTitle": "Python MLOPS Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/python-mlops-engineer-at-virtusa-3966298931?position=47&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=BizNKgEh%2FtRT4Gvs2rrxRg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Role GDT WS\n\nPython MLOPS\n\nHadoop EngineerExp\n\n5+Location Pune/HyderabadRole DescriptionML Engineers who will contribute across the entire ecosystem, including Python batch processes, REST API design, and creation/improvements to CI/CD pipelines. Keys Skills RequiredStrong Python skills knowledge of any other object oriented language a plusFamiliarity with ML algorithms and principlesExperience with DevOps and CI/CD any JenkinsExperience working with Big Data technologies Hadoop, HDFS, Elasticsearch, SparkExperience working with Cloud ideally GCPStrong software engineering fundamentals git, code reviews, agile team working.Familiarity with Python REST API frameworks a plus Flask, Fast APIExperience in Docker Deployment and KubernetesExperience with Airflow used as orchestrator and scheduler.",
    "companyName": "Virtusa ",
    "jobLocation": " Andhra Pradesh, India",
    "jobPostDate": "2 days ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://sg.linkedin.com/jobs/view/mlops-engineer-at-renesas-electronics-3953981018?position=48&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=7wn0qUkh5Bz9HqtomJhBnQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Company Description\n\nRenesas is one of the top global semiconductor companies in the world. We strive to develop a safer, healthier, greener, and smarter world, and our goal is to make every endpoint intelligent by offering product solutions in the automotive, industrial, infrastructure and IoT markets. Our robust product portfolio includes world-leading MCUs, SoCs, analog and power products, plus Winning Combination solutions that curate these complementary products. We are a key supplier to the world’s leading manufacturers of electronics you rely on every day; you may not see our products, but they are all around you.\n\nRenesas employs roughly 21,000 people in more than 30 countries worldwide. As a global team, our employees actively embody the Renesas Culture, our guiding principles based on five key elements: Transparent, Agile, Global, Innovative, and Entrepreneurial. Renesas believes in, and has a commitment to, diversity and inclusion, with initiatives and a leadership team dedicated to its resources and values. At Renesas, we want to build a sustainable future where technology helps make our lives easier. Join us and build your future by being part of what’s next in electronics and the world.\n\nJob Description\n\nOverview \n\nIn this role, you will be part of the AI & Cloud Engineering (ACE) Division and MLOps team. We are developing a comprehensive AI strategy that delivers a highly flexible platform to explore new Deep Learning / Machine Learning model architectures, combined with auto-tuned high performance for production environments across a wide range of hardware architectures. The platform can improve performance, developer efficiency & deployment velocity of both AI training and inference.  \n\n \n\nAs an MLOps team member, you will develop the best-in-class software toolchain for AI software & hardware to support internal and external customers, which serves as the backbone of all products in our division. You will work closely with AI engineers to build innovative software tools to power the entire AI development lifecycle from developing and analyzing AI models to testing and loading the models on the hardware. You will then integrate the tools into a software platform delivered to our customers. You will apply software development best practices to design features, improve performance and deliver software. You will gain valuable experience in developing commercial grade MLOps products and will help in driving next generation hardware software co-design for AI domain specific problems. \n\n  \n\nOur division’s mission is to use the latest AI and cloud technologies to develop the best AI inference for advanced driver safety engineers building self-driving vehicles and other high performance compute products. Renesas is the leading automotive electronics supplier globally, and this is a rare opportunity to deploy your AI software to the billions of devices we ship to customers every year. You will join our newly formed AI & Cloud Engineering organization of around 100 software engineers. Due to strong demand for our AI-related products we are planning to triple in size in the next three years, so there is lots of room for you to help us grow the team together while remaining small. We are focusing on our hiring into our Tokyo, Beijing and Singapore sites. If you are successful and living outside of these cities, we can support your relocation to one of the three sites based on team needs.\n\nResponsibilities \n\n\nDesign the AI/ML pipelines and engineering infrastructure to support internal and external machine learning systems at scale. \nDevelop and deploy scalable tools and services to handle machine learning training and inference. \nIdentify and evaluate new technologies to improve performance, maintainability, and reliability of machine learning systems. \nApply software engineering rigor and best practices to machine learning, including CI/CD, automation, etc. \nSupport model development, with an emphasis on auditability, versioning, and data security \nFacilitate the development and deployment of proof-of-concept machine learning systems. \nCommunicate with clients to build requirements and track progress\n\n\nQualifications\n\n\nBachelor’s or Master's degree in computer science, machine learning, mathematics, physics, electrical engineering or related field. \nExperience building end-to-end systems as a Platform Engineer, ML DevOps Engineer, or Data Engineer (or equivalent) \nStrong software engineering skills in complex, multi-language systems \nExperience in C/C++, Python, or other related programming language \nExperience working with cloud computing and database systems \nExperience building custom integrations between cloud-based systems using APIs \nExperience developing and maintaining ML systems built with open source tools \nExperience developing with containers and Kubernetes in cloud computing environments \nFamiliarity with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo, etc.) \nUnderstanding of software testing, benchmarking, and continuous integration \nExperience working with machine learning frameworks such as PyTorch, TensorFlow, ONNX etc. \nUnderstanding of System-on-Chip is a plus. \nAbility to speak and write in English at a business level. \n\n\nAdditional Information\n\nRenesas Electronics Corporation empowers a safer, smarter and more sustainable future where technology helps make our lives easier. The leading global provider of microcontrollers, Renesas combines our expertise in embedded processing, analog, power and connectivity to deliver complete semiconductor solutions. These Winning Combinations accelerate time to market for automotive, industrial, infrastructure and IoT applications, enabling billions of connected, intelligent devices that enhance the way people work and live. Learn more at www.renesas.com.\n\nRenesas’ mission, To Make Our Lives Easier, is underpinned by our company culture, TAGIE. TAGIE stands for Transparent, Agile, Global, Innovative and Entrepreneurial. Our goal is to embed this unique culture in everything we do to succeed as a company and create trust with our diverse colleagues, customers and stakeholders.\n\nRenesas Electronics is an equal opportunity and affirmative action employer, committed to supporting diversity and fostering a work environment free of discrimination on the basis of sex, race, religion, national origin, gender, gender identity, gender expression, age, sexual orientation, military status, veteran status, or any other basis protected by law. For more information, please read our Diversity & Inclusion Statement.",
    "companyName": "Renesas Electronics ",
    "jobLocation": " Singapore, Singapore",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "MLOps Engineer,",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-engineer-at-yo-hr-consultancy-3916006683?position=49&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=1rYpJ7NSOjZyrCrCuftHEw%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Senior Machine Learning Operations Engineer\n\nLocation: Permanent Remote\n\nContract Duration: 6 Months\n\nJob Description\n\nAs a Senior Machine Learning Operations (MLOps) Engineer, you will be instrumental in deploying robust, scalable machine learning solutions. You will ensure these are tailored to meet the expansive needs of a client in healthcare services. This role demands a high level of proficiency in machine learning technologies and programming, coupled with rigorous vetting processes to maintain the highest standards of data integrity and security.\n\nKey Responsibilities\n\n\nRapidly develop and deploy production-ready ML models, with a focus on scalability and monitoring across a broad range of applications within healthcare.\nWrite efficient, maintainable, and scalable Python code tailored to our specific business needs.\nBuild high-performance, multi-tenant deployment architectures and sophisticated model monitoring systems.\nDirectly engage with internal stakeholders to incorporate feedback and refine our ML-driven products through quick iteration cycles\nUphold stringent security protocols and processes in the deployment and maintenance of machine learning models.\nDrive the continuous advancement of MLOps practices within the healthcare industry by developing innovative solutions and advocating for best practices.\n\n\nRequirements\n\n\nMinimum 3 years of experience with transformer-based models and NLP, preferably in a healthcare context.\nStrong track record of fine-tuning, running large-scale training jobs, and managing model servers like vLLM, TGI, or TorchServe.\nProficiency in data science tools such as Pandas, Notebooks, Numpy, Scipy.\nExperience with both relational and non-relational databases.\nExtensive experience with TensorFlow or PyTorch, and familiarity with HuggingFace.\nKnowledge of model analysis and experimentation frameworks such as MLFlow, W&B, and tfma is preferred.\nComfortable with a Linux environment and stringent data security practices.\nMust pass a rigorous vetting process, including extensive background checks to ensure the highest standards of data security and integrity.\n\n\nSkills: ml,operations,pandas,experimentation frameworks,machine learning,tensorflow,relational databases,healthcare context,data science tools,data security practices,healthcare,huggingface,python,non-relational databases,linux environment,model monitoring,scalability,model analysis,numpy,machine learning operations,pytorch,mlops,transformer-based models,nlp,deployment architectures",
    "companyName": "YO HR Consultancy ",
    "jobLocation": " India",
    "jobPostDate": "2 months ago "
  },
  {
    "jobTitle": "AI/MLOps Engineer",
    "applicationLink": "https://ua.linkedin.com/jobs/view/ai-mlops-engineer-at-sandbx-3864283175?position=50&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=2igx%2BuGeE5Qbjet2IBugwQ%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "About Us:\n\nAt Apolo, we're committed to simplifying AI/ML operations for organizations. By addressing the\n\ndeployment challenges of AI/ML in varied environments, we provide cost-effective and\n\nhassle-free solutions. Our managed services and comprehensive tools allow businesses to\n\nfocus on their core objectives, ensuring seamless AI adoption and innovation without the\n\noperational complexity.\n\nThe Role:\n\nWe are looking for an AI/MLOps Engineer who will be crucial in managing and evolving our\n\nproduct deliverables. This role requires technical expertise, and a proactive mindset eager to\n\nresearch and try new technologies. Ideal candidates are resourceful, excel in problem-solving,\n\nand capable of working autonomously with minimal supervision.\n\nRequirements\n\n\nUnderstanding of ML-driven projects lifecycle\nKnowledge and hands-on experience with Kubernetes, Containerd / Docker, Helm,\n\n\nCI/CD practices, particularly with GitHub Actions\n\n\nBasic understanding of MLOps best practices (data and model versioning, experiment\n\n\ntracking, reproducibility, etc.)\n\n\nProficient in Python for scripting, automation and integration\n\n\nDesirable Skills:\n\n\nNetworking including TCP/IP, DNS, load balancing and requests routing to ensure\n\n\nsecure and efficient network operations\n\n\nExperience with Pachyderm, DVC, KubeFlow, Spark, MLFlow, Seldon or their\n\n\nalternatives\n\n\nExperience with LLM deployment at scale\n\n\n\nResponsibilities:\n\n\nBuild complex automated reproducible pipelines for the entire ML project lifecycle,\n\n\nincluding data management, experimentation, model training, deployment and\n\nmonitoring in production\n\n\nBuild reusable integrations and applications for each stage of the ML project lifecycle\nMonitor the MLOps tools/approaches landscape to actively identify solutions for various\n\n\ndomain problems\n\n\nParticipate in the development of MLOps platform services\nCommunicate with end users to understand their pain points\nOn-board end users to the MLOps platform\n\n\n\nBenefits\n\nWhat We Offer:\n\n\nWork remotely, ensuring time zones align for effective collaboration\nShape the product's direction and success by taking ownership of essential components\nSolve complex and innovative challenges\nJoin a supportive and dynamic team environment\nReceive a competitive salary and benefits package",
    "companyName": "SANDBX ",
    "jobLocation": " Kyiv, Kyiv City, Ukraine",
    "jobPostDate": "3 months ago "
  },
  {
    "jobTitle": "MLOPS",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-at-wipro-3927394562?position=51&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=xfQhf%2FqZzISykKv2UI7Bew%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Automating AI/ML model deployment and Setting up monitoring for the ML pipeline\n\n\nAutomating CI/CD pipelines to account for data, code, and model changes\nProgramming, working knowledge of machine learning algorithms and frameworks, and domain knowledge\nQuerying and working with databases, testing ML models, Git and version control, frameworks like Flask, FastAPI\nProficiency in tools such as Docker and Kubernetes\nFamiliarity with experiment tracking frameworks such as MLflow\nSetting up and automating data pipelines using tools such as Airflow, Kafka amd Rabbitmq\nProviding best practices and executing POC for automated and efficient model operations at scale.\nGood to have hands-on experience using large foundation models (e.g. LLMs) and associated tool chains (e.g. langchain) and APIs to build applications, tools and workflows for production.\n\n\nAWS MLOPS",
    "companyName": "Wipro ",
    "jobLocation": " Hyderabad, Telangana, India",
    "jobPostDate": "4 days ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://uk.linkedin.com/jobs/view/mlops-engineer-at-apron-3941664290?position=52&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=pXTox0aIdfPSSJoLZTUyCg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Apron was started by a group of people who'd spend years building products for global fintech companies. But there was one big problem no one was solving. Business payments. The kind that buy tomatoes, tools, and till rolls. The kind that keep suppliers happy and business booming. The kind that should be super simple to make and manage, and yet, aren't. Payments eat up valuable hours every week for both businesses and the accountants and bookkeepers who help them.\n\nThis is a problem that's affecting entrepreneurs. Florists and financial analysts. Brewers and brand strategists. The kind of people who build things, break things, change things. Imagine what they could do with this time instead. What would they come up with? What would they create?\n\nThat's why we built Apron as a payments powerhouse. We flip the payment experience from blocking business to boosting it. Apron pulls all things payments together - weaving into your workflow, collating conversations, turning hours into minutes. So you can put those hours to better use - plan the future, take a walk, call your mum.\n\nWe are backed by Index Ventures and Bessemer Venture Partners.\n\nWho We're Looking For\n\nWe are building a product that allows our clients to upload all invoices and receipts and get them automatically processed and ready to be paid. Our goal is to make this product number 1 on the market by the end of year.\n\nTo achieve this, we need to develop a document recognition service that operates with exceptional quality, speed, and high availability.\n\nWe are looking for an engineer to help us build the infrastructure for training and deploying the models for such a service.\n\nThe other important area is to make sure that the relevant data for model training, inference and analytics are present. This would require skills for building data pipelines, making data quality checks, database and infrastructure management.\n\nThe ideal candidate should have extensive experience and a broad understanding of the MLOps and Data Engineering field. They should be capable of identifying which technologies will be beneficial and which might be excessive for our needs, ensuring the solution remains efficient and uncomplicated.\n\nWhat You'll Be Doing\n\n\nOrganising model serving ensuring high performance on high loads. Setup monitoring dashboards and alerts\nSuggesting appropriate architecture and tooling for serving models, for example serving on GPUs if needed\nIntroducing MLOps tools for model development and serving. Dataset and models storage and versioning, reproducible models training, model estimation and metrics visualisation\nSetting up documents labelling tools and model retraining based on online feedback\nEnsuring data security in service and training pipelines\nDeveloping data pipelines, managing and optimising data infrastructure to ensure the relevant data is available for model training, inference and data analytics\nContributing to development best practices such as tests in the team\n\n\n\nRequirements\n\n\n5+ years of experience in areas related to MLOps, machine learning\nExtensive knowledge of Python and SQL (PostgreSQL preferred)\nExperience in serving machine learning models and using MLOps tools (mlflow, dvc or similar)\nBasic knowledge of machine learning algorithms, models, and statistical concepts\nExperience with cloud computing platforms (we use GCP) and containerization technologies (e.g., Docker, Kubernetes)\nExperience with data pipeline development, data management skills (airflow or similar)\nKnowledge of Kotlin is a plus - all backend code except ML services is written in this language\nExperience in running AB tests / AB testing platforms is a plus\nExperience in building infrastructure for online metrics monitoring is a plus (kafka, grafana, etc.)\n\n\n\nBenefits\n\n\nCompetitive salary and stock options\nFully expensed tech\nHealth insurance via AXA\nFlexible holidays and WFH",
    "companyName": "Apron ",
    "jobLocation": " London, England, United Kingdom",
    "jobPostDate": "1 month ago "
  },
  {
    "jobTitle": "MLOPS",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-at-wipro-3927397147?position=53&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=arNua5viDVKRxnjAFWBRxg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Automating AI/ML model deployment and Setting up monitoring for the ML pipeline\n\n\nAutomating CI/CD pipelines to account for data, code, and model changes\nProgramming, working knowledge of machine learning algorithms and frameworks, and domain knowledge\nQuerying and working with databases, testing ML models, Git and version control, frameworks like Flask, FastAPI\nProficiency in tools such as Docker and Kubernetes\nFamiliarity with experiment tracking frameworks such as MLflow\nSetting up and automating data pipelines using tools such as Airflow, Kafka amd Rabbitmq\nProviding best practices and executing POC for automated and efficient model operations at scale.\nGood to have hands-on experience using large foundation models (e.g. LLMs) and associated tool chains (e.g. langchain) and APIs to build applications, tools and workflows for production.\n\n\nAWS MLOPS",
    "companyName": "Wipro ",
    "jobLocation": " Bengaluru, Karnataka, India",
    "jobPostDate": "4 days ago "
  },
  {
    "jobTitle": "Junior MLOps Tester",
    "applicationLink": "https://www.linkedin.com/jobs/view/junior-mlops-tester-at-tekintegral-3888465092?position=54&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=ym2MCAuI3fOhCy78yOZmkg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Title: ML Software Engineer x2 openings\n\nVisa: Any except H1B and OPT/CPT\n\nLocation: Prioritizing candidates in the Boston area who can travel to Westbrook, Maine once a month\n\nMode of Interview: Video 2 rounds\n\n\nData science & pathologist - build visualizations for domain users -\nWeb development - D3.js - image data - clinical information\nPython programming\nML teck-stacks - DataBricks - Amazon EC2, S3 - Docker, Kubernetes\nWorking closely with DS in PieTorch - nice to have\nData sets interfacing with - large-scale data sets -\nComputer vision background - would be nice - leaning more towards python programming",
    "companyName": "TekIntegral ",
    "jobLocation": " Westbrook, ME",
    "jobPostDate": "2 months ago "
  },
  {
    "jobTitle": "Data Engineer MLOPS/AI Engineer - NL",
    "applicationLink": "https://nl.linkedin.com/jobs/view/data-engineer-mlops-ai-engineer-nl-at-capgemini-3966594239?position=55&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=xfXvbGDHk9GK8wT19iCTEg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Blue Harvest is a rapidly growing international software consultancy company that strives to provide first-rate engineers with both excellent technical abilities and soft skills.\n\nAt Blue Harvest, we believe that people can improve the world through the power of technology. We do this by creating a nurturing environment that promotes growth and creative thinking.\n\nWe enable our engineers and customers with innovative solutions to address some of the most challenging problems out there.\n\n\nYou have a passion for innovation and know-how to use your engineering skills to give our clients a solid lead in the digital world. You will work in multidisciplinary teams on innovative solutions.\nYou advise and support clients both during the initial scoping and pre-sales cycle as well as the implementation of proposed solutions and post-sales engineering activities.\nYou are going to ingest and process the raw data of several large international corporations. Next to that you will lead teams and create reusable data solutions.\nYou will be exposed to large volumes of data and related processing workloads. And of course a lot of customer contact in which you advise them on how to maximize the value of their data.\nYou will contribute to Blue Harvest's vision and help us build our data innovation portfolio;\nYou will be part of a culture with a high bar of engineering and emotional intelligence standards where development paths are self-determined within a mentor-led environment to support and guide these growth opportunities.\n\n\nYou will become part of Blue Harvest and join our Engineering Teams with different knowledge and varying levels of experience in the field. Everyone is passionate about Technology and the challenge that working within financial services offers.\n\nOf course, you will get a competitive salary with other interesting benefits. But more importantly, you will work at a fantastic and pleasant place where you can do more than just engineering. You will be learning, developing yourself, organizing events and speaking at conferences. And you will have the best Friday afternoon beers in our office in Utrecht.\n\nDo you have any further questions about this job? Get in contact with your recruiter, Maarten di Pietro.",
    "companyName": "Capgemini ",
    "jobLocation": " Utrecht, Utrecht, Netherlands",
    "jobPostDate": "1 day ago "
  },
  {
    "jobTitle": "MLOps Engineer H/F",
    "applicationLink": "https://fr.linkedin.com/jobs/view/mlops-engineer-h-f-at-inetum-3957726462?position=56&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=3qlMtLr%2Bzmx%2BPMgfGbTlSA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Détail de l'offre\n\nInformations générales\n\nEntité de rattachement Inetum est un leader européen des services numériques. Pour les entreprises, les acteurs publics et la société dans son ensemble, les 28 000 consultants et spécialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent à la performance, à l'innovation et au bien commun.\n\nPrésent dans 19 pays au plus près des territoires, et avec ses grands partenaires éditeurs de logiciels, Inetum répond aux enjeux de la transformation digitale avec proximité et flexibilité.\n\nPorté par son ambition de croissance et d'industrialisation, Inetum a généré en 2023 un chiffre d'affaires de 2,5 milliards d'€.\n\nPour répondre à un marché en croissance continue depuis plus de 30ans, Inetum a fait le choix délibéré de se recentrer sur 4 métiers afin de gagner en puissance et proposer des solutions sur mesure, adaptées aux besoins spécifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications à façon (Inetum Technologies), l'implémentation de progiciels (Inetum Solutions) et sa propre activité d'éditeur de logiciels (Inetum Software). Inetum a conclu des partenariats stratégiques avec 4 grands éditeurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une stratégie d'acquisitions dédiée afin d'entrer dans le top 5 européen sur ces technologies et proposer la meilleure expertise à ses clients.\n\nTous nos postes sont ouverts aux personnes en situation de handicap.\n\n\n\n\nDescription du poste Métier\n\nInnovation - Technologique\n\nIntitulé du poste\n\nMLOps Engineer H/F\n\nContrat\n\nCDI\n\n\n\n\nDescription De La Mission\n\n\n\n\nAs a Data Engineer / MLOps Engineer at Inetum's FabLab, you will play a crucial role in driving the development and implementation of machine learning models and data-driven solutions. Collaborating closely with cross-functional teams, you will leverage your expertise in mathematical techniques and ML frameworks to deliver innovative solutions that address complex business challenges.\n\n\n\n\nResponsibilities\n\nCollaborate with stakeholders to understand business requirements and translate them into mathematical and ML-based solutions.\nDesign, develop, and implement machine learning models and algorithms for research projects, internal products, and client projects.\nConduct exploratory data analysis, feature engineering, and model validation to ensure the robustness and accuracy of ML solutions.\nWork closely with software engineers to integrate ML models into production systems and deploy them at scale.\ntay abreast of the latest advancements in ML techniques and frameworks, and proactively apply them to enhance model performance and efficiency.\nParticipate in research initiatives to explore emerging technologies and methodologies, and contribute to the development of innovative solutions within the FabLab.\n\n\n\n\nProfil\n\nMaster's degree or Ph.D in Computer Science, Engineering, Mathematics, or related field.\n2 years of hands-on experience in data science, machine learning, or related roles.\nStrong proficiency in mathematical techniques such as probability, statistics, and linear algebra.\nExpertise in Python programming and experience with ML libraries/frameworks (e.g., TensorFlow, scikit-learn, PyTorch).\nSolid understanding of data processing techniques and frameworks (e.g., pandas, Spark).\nExperience working on research projects and industry applications, with a proven track record of delivering high-quality ML solutions.\nExcellent communication skills with the ability to collaborate effectively with cross-functional teams and explain technical concepts to non-technical stakeholders.\n\n\n\n\nPreferred Qualifications\n\nExperience with deep learning techniques and frameworks (e.g., CNNs, LSTMs).\nKnowledge of cloud platforms and services (e.g., Azure, AWS, Google Cloud).\nFamiliarity with big data technologies and distributed computing frameworks.\nAbility to work independently and drive projects from conception to completion.\nStrong problem-solving skills and a passion for exploring innovative solutions to complex problems.\n\n\n\n\nBenefits\n\nFlexible work arrangements, including remote work options with regular visits to Paris.\nProfessional development and training opportunities. Collaborative and inclusive work culture.\nOpportunity to work on cutting-edge projects at the intersection of innovation and technology within the Innovation Business Unit.\n\n\n\n\nHow to Apply If you are passionate about leveraging mathematical techniques and machine learning to drive innovation and thrive in a dynamic and collaborative environment, we want to hear from you! Please submit your resume and a cover letter outlining your relevant experience and why you are interested in joining Inetum as a Data Scientist / ML Engineer. We look forward to reviewing your application and discussing how you can contribute to our team.\n\n\n\n\n\n\n\nLocalisation du poste Localisation du poste\n\nFrance, Ile-de-France, 93 Seine-Saint-Denis\n\nVille\n\nSaint-Ouen Sur Seine\n\nCritères candidat Niveau d'études min. requis\n\nBac+5\n\nNiveau d'expérience min. requis\n\nPlus de 2 ans",
    "companyName": "Inetum ",
    "jobLocation": " St.-Ouen, Île-de-France, France",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOps Practices_CBS",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-practices-cbs-at-codersbrain-3720304735?position=57&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=bhiDMrME0Dgx6lchJeGmqg%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Company Overview\n\nCoders Brain Technology Pvt. Ltd. operates in the None industry.\n\nRole And Responsibilities\n\n\nInfluence the technology landscape in the team\nDevelop tools, frameworks, and custom components for machine learning platforms\nDesign, develop, and maintain large-scale data and cloud infrastructure for machine learning projects\nImplement CICD flow and automation for code deployment\nCreate efficient and scalable solutions for production environments on GCP\nExplore the capabilities of Large Language Models\nScale AI and ML solutions using GCP and Vertex AI\n\n\nCandidate Qualifications\n\n\nExperience working with open-source technologies such as Seldon, MLFlow, Feast, KNative, Apache Kafka, etc.\nExperience with CICD tools like Jenkins or Github Actions\nStrong knowledge of Dockerization, Kubernetes (k8s), and REST API\nSolid experience in MLOps practices, developing ML Pipelines, and deploying ML Models to production\nStrong background in Python Programming\nHands-on experience in GCP and Vertex AI\nSolid foundations in DevOps principles and modern DevOps practices\nFamiliarity with agile ways of working, team collaboration, data-driven development, reliable and responsible experimentation\n\n\nRequired Skills\n\n\nMLOps Practices\nCICD tools\nREST API\n\n\nSkills: k8s,seldon mlflowfeast,rest,rest api,cicd tools,k-native,jenkins,github,apache,kafka,mlops practices",
    "companyName": "CodersBrain ",
    "jobLocation": " Delhi, India",
    "jobPostDate": "9 months ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-engineer-at-yo-hr-consultancy-3961680581?position=58&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=z%2FU0Bt3oI%2Fb0xCmwzuG5ug%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Senior Machine Learning Operations Engineer\n\nExperience: 6 - 18 Years\n\nLocation: Permanent Remote\n\nMust-Have\n\nMinimum 4 years of experience with transformer-based models and NLP, preferably in a healthcare context.\n\nStrong track record of fine-tuning, running large-scale training jobs, and managing model servers like vLLM, TGI, or TorchServe.\n\nProficiency in data science tools such as Pandas, Notebooks, Numpy, Scipy.\n\nStrong proficiency in spoken and written English language.\n\nBudget: 25-40 LPA\n\nType of employment: FTE\n\nJob Summary\n\nAs a Senior Machine Learning Operations (MLOps) Engineer, you will be instrumental in deploying robust, scalable machine learning solutions. You will ensure these are tailored to meet the expansive needs of a client in healthcare services. This role demands a high level of proficiency in machine learning technologies and programming, coupled with rigorous vetting processes to maintain the highest standards of data integrity and security.\n\nKey Responsibilities\n\n\n? Rapidly develop and deploy production-ready ML models, with a focus on scalability and monitoring across a broad range of applications within healthcare.\n? Write efficient, maintainable, and scalable Python code tailored to our specific business needs.\n? Build high-performance, multi-tenant deployment architectures and sophisticated model monitoring systems.\n? Directly engage with internal stakeholders to incorporate feedback and refine our ML-driven products through quick iteration cycles.\n? Uphold stringent security protocols and processes in the deployment and maintenance of machine learning models.\n? Drive the continuous advancement of MLOps practices within the healthcare industry by developing innovative solutions and advocating for best practices.\n\n\nRequirements\n\n\nMinimum 3 years of experience with transformer-based models and NLP, preferably in a healthcare context.\nStrong track record of fine-tuning, running large-scale training jobs, and managing model servers like vLLM, TGI, or TorchServe.\nProficiency in data science tools such as Pandas, Notebooks, Numpy, Scipy.\nExperience with both relational and non-relational databases.\nExtensive experience with TensorFlow or PyTorch, and familiarity with HuggingFace.\nKnowledge of model analysis and experimentation frameworks such as MLFlow, W&B, and tfma is preferred.\nComfortable with a Linux environment and stringent data security practices.\n? Must pass a rigorous vetting process, including extensive background checks to\nensure the highest standards of data security and integrity.\n\n\nSkills: machine learning operations,experimentation frameworks,ml,data security practices,mlops,tensorflow,operations,models,deployment architectures,relational and non-relational databases,managing model servers,fine-tuning,model monitoring systems,scalability,model analysis,machine learning,mlflow,mlops practices,running large-scale training jobs,healthcare context,healthcare,notebooks,relational databases,numpy,w&b,pytorch,transformer-based models,linux environment,huggingface,scipy,python,non-relational databases,python code,pandas,data science tools,model monitoring,model servers,tfma,security protocols,nlp",
    "companyName": "YO HR Consultancy ",
    "jobLocation": " India",
    "jobPostDate": "1 week ago "
  },
  {
    "jobTitle": "MLOPS Engineer",
    "applicationLink": "https://in.linkedin.com/jobs/view/mlops-engineer-at-ltimindtree-3951024893?position=59&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=o0ChimhhvT4Z5xZjcIGlrA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Please find below JD:\n\nTotal Experience-5 to 10 Years\n\nJob Location- Bangalore\n\n\n\n\nSenior MLOps Engineer :\n\nRole:\n\nCloud Solutions Design and Implementation:\n\nDevelop and implement robust cloud solutions for ML applications, including Gen AI, utilizing AWS, Azure, or GCP.\n\nBuild MLOps pipelines on both cloud and on-premise solutions.\n\nCI/CD Pipeline Orchestration:\n\nDesign and manage CI/CD pipelines using GitLab CI, GitHub Actions, Circle CI, Airflow, or similar tools.\n\nData Pipeline Implementation:\n\nConstruct efficient data pipelines for both streaming and batch data.\n\nEstablish and maintain data lakes and feature stores.\n\nData Science Model Lifecycle Management:\n\nReview data science models and execute code refactoring, optimization, containerization, deployment, versioning, and continuous monitoring.\n\nConduct testing, validation, and automation of data science models.\n\nCollaboration and Documentation:\n\nWork closely with a multidisciplinary team of data scientists, data engineers, and architects.\n\nDocument and communicate processes effectively.\n\nBackground:\n\nBachelor’s degree + 5 years or Master's degree + 3 years of relevant experience or PhD degree in computer science, electrical engineering, or related field.\n\n#EXP[7-15]\n\nPractical experience with setting up and managing ML training and data pipelines in production.\n\nSolid knowledge in at least a few of the following tools: Docker, Kubernetes, Kubeflow, Airflow, Mesos, SLURM, MLFlow, Metaflow.\n\nExperience with data versioning tools like DVC.\n\nFamiliarity with Infrastructure as Code (IaC) to define and deploy infrastructure.Strong software development skills in Python.\n\nPreferred Qualifications:\n\nPractical experience with Linux, version control systems (Git), build systems (Make, CMake, Autotools), and code review tools (Gerrit, Gitlab, Bitbucket).\n\nKnowledge in C/C++, JavaScript.",
    "companyName": "LTIMindtree ",
    "jobLocation": " Bengaluru, Karnataka, India",
    "jobPostDate": "2 weeks ago "
  },
  {
    "jobTitle": "MLOps Engineer",
    "applicationLink": "https://fr.linkedin.com/jobs/view/mlops-engineer-at-linagora-3967691755?position=60&pageNum=0&refId=Q2nm%2B15WSsFF5WI%2B6IqVlQ%3D%3D&trackingId=TL5PYgCxoCMmLV%2FIcE7lDA%3D%3D&trk=public_jobs_jserp-result_search-card",
    "jobDescription": "Depuis sa création, LINAGORA défend un numérique éthique, une « 3ème Voie Numérique », respectueuse des droits de chacun, responsable, inclusive et durable, capable d’apporter une réelle alternative aux géants américains et chinois.\n\nParmi ses logiciels phares LINAGORA, développe Twake Workplace qui se positionne comme une alternative 100 % libre aux solutions des GAFAM. Twake Workplace est disponible sous la forme d’une plate-forme complète ou bien module par module. Elle comprend notamment :\n\nTwake Mail, une puissante messagerie moderne basée sur le protocole JMAP et le serveur d’e-mail JAMES de la fondation Apache dont LINAGORA assure le leadership technique ;\nTwake Chat, une solution de communications instantanées pour entreprise développée sur le protocole MATRIX et compatible avec la solution de chat de l’État Français, Tchap ;\nTwake Drive, un plateforme collaborative très facile d’usage permettant le travail en groupe grâce à OnlyOffice.\n\n\n\n\nEn plus de Twake Workplace, LINAGORA développe LinShare qui est une solution de partage sécurisé de fichiers volumineux.\n\nDepuis près de 10 ans, LINAGORA travaille également dans le domaine de la voix et développe ses propres algorithmes de transcription et modèles de langage. Ces technologies se retrouvent dans LinTO, une plateforme Open Source d’intelligence conversationnelle. LinTO permet l’enregistrement de réunions, leur transcription et leur édition en mode collaboratif afin de les organiser et de pouvoir en tirer partie grâce à l’intelligence artificielle.\n\n\n\n\nLINAGORA est aussi un acteur clef du domaine de l’intelligence artificielle Open Source. LINAGORA propose une gamme complète de services et de produits cognitifs basés sur des modèles fondations sobres, compacts, Open Source et souverains. Ces derniers sont développés en mode communautaire avec un ensemble d’acteurs académiques, organisations publiques et privées réunis au sein de la communauté OpenLLM France.\n\n\n\n\nEn plus de son offre logicielle, LINAGORA propose son offre unique d’OSSA (Open Source Software Assurance) qui assure le Maintien en Conditions Opérationnelles (MCO) et le Maintien en Conditions de Sécurité (MCS) des logiciels Open Source utilisés dans les systèmes d’informations les plus critiques de ses grands clients.\n\nEnfin, LINAGORA accompagne ses clients avec une gamme complète de services professionnels : conseil, expertise technique, développement, formation.\n\nPrésent sur tout le territoire français, LINAGORA dispose également de bureaux au Vietnam, en Tunisie et vend ses logiciels et services partout dans le monde.\n\n\n\n\nPrésentation du poste :\n\nVous serez rattaché(e) à notre équipe Conseil IA. Dans cette équipe vous pourrez compter sur notre un lead d’équipe, ainsi qu’une équipe de 5 personnes, basé à Issy-les-Moulineaux, sur l’Île Saint-Germain. Nous avons en parallèle, une équipe R&D également spécialisée sur l’IA, basé à Toulouse avec qui vous collaborerez.\n\nUne charte est également en place concernant le télétravail.\n\nVos missions :\n\nEn tant qu'ingénieur MLOps / LLMOps, vous serez responsable de la conception, du déploiement et de la gestion de pipelines de modèles de machine learning, ainsi que de l'automatisation des processus de déploiement et de surveillance des modèles en production. Vous travaillerez en étroite collaboration avec nos équipes de développement logiciel, de data science et d'infrastructure pour garantir le déploiement et le fonctionnement de nos solutions à grande échelle.\n\nVos principales responsabilités seront de :\n\n- Participer à la conception et à la mise en œuvre de l'architecture MLOps / LLMOps ;\n\n- Collaborer avec les équipes de développement logiciel et de data science pour comprendre les besoins et les traduire en solutions MLOps ;\n\n- Automatiser les processus de déploiement, de surveillance et de gestion des modèles en production ;\n\n- Rester à jour sur les dernières tendances et les meilleures pratiques en matière de MLOps.\n\n\n\n\nProfil recherché :\n\nNous sommes à la recherche d'un Ingénieur MLOps / LLMOps talentueux et expérimenté pour rejoindre une équipe en pleine croissance.\n\nNous recherchons une personne ayant une formation supérieure (minimum Bac+5) en informatique, ingénierie, data science ou un domaine similaire, avec une expérience réussie dans un poste similaire d’au moins 3 ans.\n\nNous recherchons également une personne communicante, ayant le sens du service, organisée, rigoureuse et agile pour mener à bien ses missions.\n\nLa maîtrise de l’anglais est aussi indispensable.\n\nCompétences Techniques indispensables :\n\nCapacité à concevoir et mettre en œuvre des solutions cloud ;\nConnaissance approfondie des outils et des technologies MLOps / LLMOps tels que Docker, K8s, Kubeflow, MLflow, Serveurs d'inférence et,\nExpérience en déploiement de modèles LLM en production sera un plus ;\nMaîtrise des outils et des technologies de déploiement continu (CI/CD) ;\nExcellentes compétences en programmation en Python ;\nBonne compréhension de Linux.",
    "companyName": "LINAGORA ",
    "jobLocation": " Issy-les-Moulineaux, Île-de-France, France",
    "jobPostDate": "9 hours ago "
  },
  {
    "jobTitle": "",
    "applicationLink": "https://pl.linkedin.com/in/magda-pikosz?trk=public_jobs"
  }
]